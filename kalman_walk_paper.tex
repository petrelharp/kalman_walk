\documentclass{article}
\usepackage{amsmath, amssymb, color, xcolor, amsthm}
\usepackage{graphicx, wrapfig, float, caption, dsfont, bbm, xfrac}
\usepackage{fullpage}
\usepackage[backref=page, hidelinks, colorlinks=true, citecolor=blue!60!black!100]{hyperref}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, shapes}
\usepackage{caption, subcaption}
\usepackage{natbib} % gives us \citet: Author (year) and \citep: (Author; year)
\usepackage{authblk}

\usepackage{multicol}

% for comments in margins or not
\newif\ifmargincomments
\margincommentstrue
% \margincommentstrue
\ifmargincomments
    \usepackage{todonotes}
    \usepackage[left=1cm,right=6.5cm,top=3cm,bottom=3cm,nohead,nofoot,marginparwidth=6cm]{geometry}
    \newcommand{\plr}[1]{\todo[color=blue!25]{#1}}
    \newcommand{\js}[1]{\todo[color=green!25]{#1}}
    % inline comment version
    \newcommand{\plri}[1]{{\color{blue}\it #1}}
\else
    \newcommand{\plr}[1]{{\color{blue}\it #1}}
    \newcommand{\plri}[1]{\plr{#1}}
\fi

\newcommand{\jss}[1]{{\color{olive}\it #1}}
% \newcommand{\ddt}{\frac{d}{dt}}
\newcommand{\ddt}{\dot}
\newcommand{\ro}{{ro}}
\newcommand{\nro}{{\bar{r}o}}
\newcommand{\rno}{{r\bar{o}}}
\newcommand{\nrno}{{\bar{r}\bar{o}}}
\newcommand{\reachable}{\mathcal{R}}
\newcommand{\unobservable}{\bar{\mathcal{O}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\pda}{\frac{\partial}{\partial A_{ij}}}
\newcommand{\ind}{\mathds{1}}

\newcommand{\calA}{\mathcal{A}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\diag}{\text{diag}}
\newcommand{\1}{\mathbbm{1}}

\newcommand{\Sys}{\mathcal{S}}
\newcommand{\allS}{\mathcal{A}}
%\newcommand{\allS}{\mathcal{A}}

% fitness as a fn of distance
\newcommand{\fit}{\mathcal{F}}
% fitness as a fn of A
\newcommand{\fitx}{\mathcal{F}}
% set of optimal coefficients
\newcommand{\optx}{\mathcal{X}}
% optimal phenotype
\newcommand{\optph}{\Phi_0}
% distance in phenotype space
\newcommand{\dph}{d}
% incompatibility
\newcommand{\Incompat}{\mathcal{I}}

\DeclareMathOperator{\spn}{span}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\begin{document}

\section*{Rapid speciation despite conservation of phenotype}
{\centering
Joshua S. Schiffman$^{\dagger}$ \qquad Peter L. Ralph$^{\dagger \ddagger}$ \\
$^{\dagger}$University of Southern California, Los Angeles, California \qquad 
$^{\ddagger}$University of Oregon, Eugene, Oregon \\
\texttt{jsschiff@usc.edu} \qquad 
\texttt{plr@uoregon.edu}
\\
}

% Other title ideas:
%
% More than one way to grow a cat: speciation despite conservation of phenotype
%
% More than one way to grow a cat: regulatory network drift and speciation
%
% Rapid speciation despite conservation of phenotype
%
% More than one way to grow a cat: regulatory network redundancy and speciation
%
% Neutral network drift leads to incompatibilities on the same time scale as genetic drift
%
% More than one way to grow a cat: can network drift lead to speciation?
%
% How fast does network drift create incompatibilities?
%
% Beyond the snowball: a quantitative model of incompatibility accumulation
%
% Systems drift and speciation: more than one way to grow a cat
%
% An explicit model of neutral regulatory network evolution, with applications
% to the rate of accumulation of hybrid incompatibility
%
% Evolutionary conservation of phenotype does not entail conservation of the underlying
% molecular mechanism leading to rapid speciation
%
% The evolution of phenotype-invariant gene networks rapidly leads to hybrid incompatibiliy
%
% Evolutionary network rewiring can rapidly lead to hybrid incompatibility despite
% phenotypic conservation
%
% Hybrid incompatibilities can evolve rapidly due to developmental systems drift
%
% Evolutionary systems theory and speciation 

\begin{abstract}
We introduce an analytical theory to study the evolution of biological systems, such as gene regulatory networks. The evolutionary conservation of phenotype under selective and environmental stasis does not necessitate conservation of the underlying mechanism, as distinct molecular pathways can realize identical phenotypes. Here we give an exact expression for the set of all linear mechanisms with identical phenotypes, and expect evolution under neutrality to explore this set. We employ a quantitative genetic approach to model evolution under neutrality as a random process over the set of all phenotype-invariant mechanisms: only mutational tweaks to the pathway that leave the phenotype invariant are optimally fit. We show that there is never a unique linear system architecture for any phenotype and that the evolutionary exploration of these distinct and mutationally connected mechanisms can lead to the rapid accumulation of hybrid incompatibilities between allopatric populations and thus lead to the rapid formation of new species -- in fewer generations than there are breeding individuals in a population.
\end{abstract}

\plr{Additional ideas to consider adding:}
\begin{itemize}
    %\item Haldane's rule (easy point in discussion: makes F1s look like F2s)
    %\item add point about F1: quartic and F2: quadratic to results and maybe abstract/discussion
    %\item hybrid vigor (need to do calculation)
    \item discuss linearity, linearization, and canalization in introduction
    %\item obtain estimates of variation in $A$ from thermodynamic occupancy model
\end{itemize}

%\plri{Note: in the \LaTeX source I'm putting in semantic linebreaks, so it's easy to edit and move around phrases and ideas.}

%\plri{Need to come up with a consistent term for ``the $A_{ij}$''s. -- ``regulatory coefficients''? ``genotype''?}

%%%%%%%%%%%%%%%%%%%%%%
%\begin{multicols}{2}
\section*{Introduction}
Bridging the gulf between an organism's genome and phenotype is a poorly understood and complex molecular machinery. 
Progress in a suite of biological subdisciplines is stalled by our general lack of understanding of this molecular machinery: with respect to both its function and evolution. 
There does exist a growing body of data on the evolutionary histories and molecular characterizations of particular gene regulatory networks \citep{jaeger2011gap, davidson2006gene, israel2016comparative}, as well as thoughtful verbal and conceptual models \citep{true2001developmental, gwagner1, weiss2000phenogenetic, edelman2001degeneracy}. 
However, verbal theories are often insufficient, if not downright misleading \citep{servedio2014not}. 
This is especially pertinent given the staggering complexity and scope of contemporary research programs. 
This outlook necessitates the advancement of conceptual frameworks of such precision, 
only mathematics will suffice, as models allow the development of concrete numerical predictions. 
%Previously it has been suggested that any idealized study of evolution is incomplete 
%without a mathematically sufficient description of the genotype, phenotype, and transformation from one to the other \citep{Lewontin1974genetic}.
\plr{probably some more recent Wagner papers in this line as well?}
%Here we outline an analytical theory to study the evolution of biological systems, borrowing insight and methods from control engineering, systems identification, and dynamical systems theory. 
%
%Presently, we focus on the neutral evolution of genetic regulatory networks. That is, we analytically describe the set of all linear gene networks (of any size) that produce identical phenotypes -- and the evolutionary paths connecting them. In the idealized case of a perfectly adapted population, constant selection, and a static environment, we observe evolution under the ``conservation of phenotype'' as a Brownian motion over phenotypically-invariant network-space. This analysis provides insight to the mechanisms and parameters important for understanding developmental systems drift, network rewiring, evolvability, epistasis, and speciation, as well as the tenuous connection between network architecture and function.
%
%
%It is commonly taught that an organism's genome contains the heritable material 
%that natural selection filters and that an organism's phenotype directly determines its
%evolutionary fitness. Between genotype and phenotype is an often complicated and poorly
%undrstood molecular machinery -- and it is a major goal common to many different disciplines
%within the life sciences to elucidate its form, function, and evolution. These aims are
%delicately intertwined and a comphrehensive understanding of a system's evolution requires
%an understanding of its function and vice versa.

The molecular machinery, interacting with the environment, and bridging genotype to phenotype
can be mathematically described as a dynamical system -- or a system of differential equations \citep{jaeger2015comet}.
 Movement in this direction is ongoing, as researchers have begun to study 
the evolution of both abstract \citep{wagner1994evolution, wagner1996does,  siegal2002waddington, bergman2003evolutionary, draghi2015robustness} and empirically inspired computational and mathematical models of gene regulatory networks \citep{mjolsness1991connectionist, jaeger2004dynamic, maria1, vitaly1, vitaly2, crombach2016gap, wotton2015quantitative, chertkova2017insilico}. If we allow the reasonable assumption that the genotype-phenotype map can be represented as a system of differential equations, we can immediately discuss its evolution and function in a much more mechanistic, yet general, manner. 

In some fields that seek to fit parametric models to experimental data, such as control
theory, chemical engineering, and statistics, it is well known that mathematical models
can fundamentally be \emph{unidentifiable} and/or \emph{indistinguishable} -- meaning that 
there can be uncertainty about an inferred model's parameters or even its claims about
causal structure, even with access to complete and perfect data \citep{bellman1970structural, grewal1976identifiability, walter1984structural}. 
%\plr{not clear what you mean by "actually"}\js{I think we discussed it's clear enough for an intro?}
Models with different parameter schemes, or even different mechanics can be equally accurate, 
but still not \emph{actually} agree with what is being modelled. 
In control theory, where electrical circuits and mechanical systems are often the focus, 
it is understood that there can be an infinite number of ``realizations'', 
or ways to reverse engineer the dynamics of a black box,
even if all possible input and output experiments on the black box are performed \citep{kalman1963mathematical, anderson1966equivalence, zadeh1976linear}. 
In chemical engineering, those who study chemical reaction networks sometimes refer to the fundamental
unidentifiability of these networks as ``the fundamental dogma of chemical kinetics'' \citep{craciun2008identifiability}. 
In computer science, this is framed as the relationship among processes that simulate one another \citep{van2004equivalence}.  
Although this may frustrate the occasional engineer or scientist, viewed from another angle,
the concepts of unidentifiability and indistinguishability can provide a starting point for
thinking about externally equivalent systems
-- systems that evolution can explore, so long as the parameters and structures can be realized biologically.
In fact, evolutionary
biologists who study convergent versus parallel evolution, and developmental homology and analogy, are very familiar with such functional symmetries; 
macroscopically identical phenotypes in even very closely related species can in fact be divergent at the molecular and sequence level 
\citep{true2001developmental, tsong2006evolution, hare2008sepsid, vierstra2014mouse, stergachis2014conservation, taylor2016diverse, matsui2015regulatory}.

In this paper we outline a theoretical framework to study the evolution of biological systems, such as gene regulatory networks. 
We focus primarily on the neutral scenario: 
that is where phenotype is conserved over evolutionary time. 
%however, this framework could be applied to a wider set of evolutionary scenarios. 
We present an analytical description of the set of all linear biological systems with identical phenotypes 
-- that is we describe the set of all gene network architectures that yield identical phenotypes in equivalent environments, and show that all linear biological systems can, in principal, can undergo systems drift and rewire. 
Under neutrality, a population will drift through the set of all possible phenotypically equivalent linear gene networks.
Consequentially, two phenotypically equivlanet yet allopatrically isolated populations, will likely produce incompatibile hybrids, despite the absence of adaptation, directional selection, or environmental change.
Under these conditions, speciation typically occurs on timescales approximately on the order of $N_{e}$ generations, where $N_{e}$ is the effective population size.
%
\section*{Gene networks as linear dynamical systems}
%  \jss{Organisms' phenotypes are constructred by gene by gene by environment interactions. Here we simply define the phenotype to be the organismal temporal molecular dynamics directly under natural selection. The \emph{what}, \emph{when}, and \emph{where}, of an organism's molecules that are physiologically or otherwise relevant for survival. 
%   Thus we say that some function $\phi(t)$ is a phenotype where, 
%  \begin{align}
%    \phi(t) = \int_{0}^{\infty} h(t) u(t) dt  ,
%  \end{align}
%  and $h(t)$ is the \emph{impulse response} of the system and $u(t)$ is the \emph{input} function, both functions of time $t$. The input can be interpreted as the environment, as initial conditions, or otherwise, depending on the biological specifics under study. The phenotype is a convolution of both the impulse response and the input, as allowed by our assumption of linearity. 
%
%  Essentially the phenotype $\phi(t)$ is a consequence of an organism's specific gene by gene interactions, given by $h(t)$, reacting further with the local environment, given by $u(t)$. 
%
%  We describe the impulse response as, 
%  \begin{align}
%    h(t) = C e^{A t} B
%  \end{align}
%  where $A$ is a gene regulatory network (although this model can be generalized to other biological networks) -- a square matrix, and $B$ filters and translates the input to the system. The form of $B$ determines precisely how the state of the external environment influences the internal gene network. $C$ filters and translates the dynamics of the system and precesily determines the output, that is, what is visible to selection. 
%
%  Generally $A$ can be any real $n \times n$ matrix, $B$ any $n \times \ell$, and $C$ any $\ell \times n$ dimensional matrix. Each $i$th row of $A$ describes the \emph{cis}-regulatory module for gene $i$, and each $j$th entry, the specific regulatory influence of gene $j$ on gene $i$. 
%
%  Although $\phi(t)$ describes the phenotype given an input, $h(t)$ describes the phenotype subject only to an impulse -- an input present initially and absent immediately thereafter. Typically, a system $\Sigma$, is defined as,
%  \begin{align}
%    \Sigma = \left\{ \begin{array}{ll} \dot{\kappa}(t) &= A \kappa(t) + B u(t) \\ \phi(t) &= C \kappa(t) \end{array} \right.
%  \end{align}
%  Variables have the same identities as described above and $\kappa(t)$ is a vector of molecule concentrations at time $t$. Therefore the molecular concentrations at a specific time are completely determined by the input and gene by gene interactions. Lastly, a portion and/or combination of these molecules, $\phi(t)$, are ``observed'' by selection (this is in constrast to $\kappa(t)$ -- the \emph{kryptotype} -- as it is ``hidden'' from direct selection).
%}
\paragraph{Systems theory}
Organisms' phenotypes are constructred by gene by gene and gene by environment interactions. Here we simply define the \emph{phenotype} to be the temporal molecular dynamics directly under natural selection. The \emph{what}, \emph{when}, and \emph{how much}, of an organism's molecules that are physiologically or otherwise relevant to survival.

Thus an organism's phenotype $\phi(t)$ -- a vector of molecular concentrations at time $t$ -- is determined both by the structure and organization of a biological system (\emph{e.g.} a gene regualtory network), given by the triple $(A,B,C)$,
and by its environment $u(t)$.

Such a biological system $\mathcal{S}$ is given by,
  \begin{align}\label{eqn:system}
    \mathcal{S} := \left\{ \begin{array}{ll} \dot{\kappa}(t) &= A \kappa(t) + B u(t) \\ \phi(t) &= C \kappa(t) \end{array} \right.
  \end{align}

Generally $A$ is any real $n \times n$ matrix, $B$ any $n \times \ell$, and $C$ any $\ell \times n$ dimensional matrix. Although many different biological systems can be modeled with this approach, for clarity, we focus on gene regulatory networks.
%
Each $i$th row of $A$ describes the \emph{cis}-regulatory module for gene $i$, and each $j$th entry, the specific regulatory influence of gene $j$ on gene $i$. 
%The $i^\text{th}$ row of $A$ contains the regulatory logic pertaining to gene $i$.
%
As such, $A_{ij}$ is the magnitude at which transcription factor $\kappa_j(t)$ regulates transcription factor $\kappa_i(t)$, and if $A_{ij} > 0$, we say that $\kappa_j$ upregulates $\kappa_i$. If $A_{ij} < 0$, we say that $\kappa_j$ down-regulates $\kappa_i$. 

The form of $B$ determines precisely how the environment influences the organism -- that is $B$ filters and translates the input to the system. $C$ filters and translates the dynamics of the system and precesily determines the output, that is, what is visible to selection.
\emph{E.g.} for a metabolic system, $C_{ij}$ is the amount the $j$th metabolite $u_j$ affects the production of the $i$th enzyme.
%

  %where $A$ is a gene regulatory network (although this model can be generalized to other biological networks) -- a square matrix, 
  %and $B$ filters and translates the input to the system. The form of $B$ determines precisely how the state of the environment influences the internal gene network. $C$ filters and translates the dynamics of the system and precesily determines the output, that is, what is visible to selection. 
%
%
Furthermore, whereas the phenotype is a subset of molecules \emph{visible} to selection, the \emph{kryptotype} includes the molecular dynamics \emph{hidden} from selection. That is $\kappa(t)$ is a vector of the system's molecular concentrations at time $t$.
%
%The structure of $B$ and $C$ determines how systems process their environment and convert krypto- to phenotypes, respectively. 
%
\plr{This "Thus" needs expanding, e.g., "the solution to this equation is unique and given by" with a reference.}

Finally, we can write the phenotype as a convolution of the system organization and the environment,
  \begin{align}
    \phi(t) = C e^{A t} \kappa(0) + \int_{0}^{t} C e^{A (t-s)} B u(s) ds ,
  \end{align}
where we refer to $h(t) := Ce^{A t}B$ as the system's \emph{impulse response}. 
%We will now lay out the model in more general terms.
%Suppose that the \emph{internal state} of the system
%is parameterized by the concentrations of a collection of $n$ molecular species,
%$S_1, \ldots, S_n$,
%and the vector of concentrations at time $t$ we denote $\kappa(t)=(\kappa_1(t),\ldots,\kappa_n(t))$.
%There are also $m$ ``input'' species, whose concentrations are determined
%exogenously to the system,
%and are denoted $u(t) = (u_1(t),\ldots,u_m(t))$,
%and $\ell$ ``output'' species, whose concentrations are denoted
%$\phi(t) = (\phi_1(t),\ldots,\phi_\ell(t))$.
%The output is merely a linear function of the internal state:
%\begin{align*}
%    \phi_i(t) = \sum_j C_{ij} \kappa_i(t).
%\end{align*}
%Since $\phi$ is what natural selection acts on, we refer to it as the \emph{phenotype},
%and sometimes in contrast refer to $\kappa$ as the \emph{kryptotype},
%as it is ``hidden'' from direct selection.
%The rate at which the $i^\text{th}$ species is produced
%is a weighted sum of the concentrations of the other species
%as well as the input:
%\begin{align*}
%    \ddt \kappa_i(t) = \sum_j A_{ij} \kappa_j(t) + \sum_r B_{ir} u_r(t) .
%\end{align*}
%In matrix notation, this is written more concisely as
%\begin{align} \label{eqn:lti_system}
%    \ddt \kappa(t) &= A \kappa(t) + B u(t) \\
%    \phi(t) &= C \kappa(t) .
%\end{align}
 \begin{example}[Oscillating gene network: cell cycle control]\label{ex:oscillator}
    Cellular division is governed by many different processes, however it is thought that its rhythm is partially controlled by oscillating gene transcription \citep{orlando2008global}. Here we consider a simplified model of oscillating gene transcription.

    Suppose gene-2 up-regulates the transcription of gene-1 and that gene-1 down-regulates gene-2 with equal magnitudes, whose concentrations are given by $\kappa_1(t)$ and $\kappa_2(t)$. Furthermore, suppose that only the dynamics of gene-1 are consequential to the cell cycle (perhaps the amount of gene-1 activates another downstream gene network). Lastly suppose that the production of both genes is equally stimulated by an impulse of a molecule present immediately after division.

    If the rate each of these genes is expressed is a linear function of their concentrations, the dynamics of the system is given by
    \begin{alignat*}{2}
      %\left\{ \begin{array}{ll} 
      \dot{\kappa_{1}}(t) &= &&\kappa_{2}(t) + u(t) \\
        \dot{\kappa_{2}}(t) &= - &&\kappa_{1}(t) + u(t) \\
        \phi(t) &= &&\kappa_{1}(t)   .
      %\end{array} \right.
    \end{alignat*}
Equivalently, in matrix form the system regulatory coefficients are given as,
    $A \!=\! \left[\begin{smallmatrix} 0 & 1 \\ -1 & 0 \end{smallmatrix}\right] ,\ B \! =\! \left[\begin{smallmatrix} 1 \\ 1 \end{smallmatrix}\right] , \ C \! =\! \left[\begin{smallmatrix} 1 & 0 \end{smallmatrix}\right]$
  %  \begin{align*}
  %    A = \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} , \qquad B = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, \qquad C = \begin{bmatrix} 1 & 0 \end{bmatrix}
  %  \end{align*}
 %       The oscillatory system $\Sigma$ is thus given as
 %   \begin{align*}
 %     \Sigma = \left \{ \begin{array}{ll} \dot{\kappa}(t) &= \begin{bmatrix} 
 %       0 & 1 \\ 
 %      -1 & 0 
 %       \end{bmatrix} \kappa(t) + \begin{bmatrix} 1 \\ 1 \end{bmatrix} u(t) \\ 
 %         \phi(t) &= \begin{bmatrix} 1 & 0 \end{bmatrix} \kappa(t) \end{array} \right.
 %    \end{align*}
      
      Since the input is simply an impulse, its phenotype is equivalent to its impulse response,
      \begin{align*}
        \phi(t) = h(t) = \sin t + \cos t  .
      \end{align*}

    \begin{figure}[H]
       % \begin{center} 
      \centering
         \begin{tabular}{cc}
            \begin{tikzpicture}
            \begin{scope}[every node/.style={circle,thick,draw}]
                \node (A) at (0,0) {$\kappa_{1}$};
                \node[dashed] (B) at (3,0) {$\kappa_{2}$};
                \node[shape=rectangle] (U) at (1.5,1.5) {input};
                \node[shape=rectangle] (y) at (1.5,-1.5) {output};
            \end{scope}

            \begin{scope}[>={Stealth[black]},
                          every node/.style={fill=white,circle},
                          every edge/.style={draw=black, thick}]
                \path [->, >=Rectangle] (A) edge[bend left] node {\tiny $-1$} (B);
                \path [->] (B) edge[bend left] node {\tiny $1$} (A); 
                \path[->] (U) edge[dashed] node {\tiny $1$} (A);
                \path[->] (U) edge[dashed] node {\tiny $1$} (B);
                \path[->] (A) edge[dashed,bend right] node {\tiny $1$} (y);
            \end{scope}
            \begin{scope}[>={Stealth[black]},
                          every edge/.style={draw=black, thick}]
                %\path [->] (A) edge[loop left] node {\tiny $\lambda_{1}$} (A);
                %\path [->] (B) edge[loop left] node {\tiny $\lambda_{2}$} (B);
            \end{scope}

            \end{tikzpicture} &
      \includegraphics[width=0.5\textwidth, height=0.125\paperheight]{osc_impulse}
   \end{tabular}
  %  \end{center}
      \caption{(Left) Graphical representation of the cell cycle control gene network, and (right) plot of the phenotype $\phi(t)$ against time $t$.}
    \end{figure}
      We return to the evolution of such a system below.
  \end{example}


  \paragraph{Phenotypically equivalent gene networks}

%\plr{This paragraph feels like the introduction.}
%The literature is filled with detailed observations of molecular systems and their diversity. 
%\plr{Diversity doesn't imply systems drift -- only if the diverse systems are homologous.}
%There are examples of significant diversity in the networks underlying processes such as 
%circadian rhythm \citep{sancar2008intelligent}, 
%cell cycle control \citep{cross2011evolution, kearsey2003enigmatic}, 
%pattern formation \plr{cite?}, 
%and metabolism \citep{lavoie2009rearrangements, martchenko2007transcriptional, dalal2016transcriptional, christensen2011unique, hartl2007induction, alam2013aspergillus}. 
Despite a symmetry in functionality or phenotype systems can often differ, sometimes substantially, at the molecular level. 
How many different mechanisms have the same function? 
Gene regulatory networks with identical phenotypes do not necessarily have identical kryptotypes.
%
%Any linear and minimal gene network 
%-- minimal, informally meaning that the system's phenotype is achieved with the fewest possible genes ($n=\min$, see \ref{apx:kalman})
%-- has an identical impulse response and thus phenotype given identical inputs $u(t)$, up to a change of coordinates. 
%  \begin{equation}
%    \begin{aligned}
%      h(t) &= C e^{A t} B 
%      = C V^{-1} V e^{A t} V^{-1} V B \\
%      &= C V^{-1} e^{V A V^{-1} t} V B 
%      = \bar{C} e^{\bar{A} t} \bar{B}
%    \end{aligned}
%  \end{equation}
%Two gene networks, $\mathcal{S} = ( A, B, C )$, and $\bar{\mathcal{S}} = (\bar{A} = VAV^{-1}, \bar{B} = VB, \bar{C} = CV^{-1} )$, 
%have the same phenotype, for all possible inputs, if and only if they are related by a change of coordinates. 
%
%Although systems may not be identifiable beyond a change of coordinates, at present we are primarily interested in a subset of these systems. 
%That is, systems that not only have equivalent external dynamics, but also equivalent input and output relationships. 
%\plr{clarify that you mean actually having the same $B$ and $C$. (at first I read "input and output relationship" as the mapping $u \to \phi$),
%    i.e. behaviour across many possible inputs.}
%Formally, this means systems related by a change of coordinates (any invertible matrix $V$) that leaves $B$ and $C$ invariant:
%  \begin{align}
%    VB &= B \implies \bar{B} = B \\
%    CV &= C \implies \bar{C} = C
%  \end{align}
%\plr{this sentence lacks an object (or some sentence part?)}
%In other words systems with varying gene regulatory network architectures yet identical selection pressures, environment, and phenotype.
%
%Define $V(\tau)$ as the parameterized change of coordinates matrix that preserves $B$ and $C$, with $\tau$ a vector of free parameters. The set of \emph{all} phenotypically invariant (minimal) gene networks is, 
 % \begin{align}
 %   A(\tau) = V(\tau) A(0) V^{-1}(\tau) ,
 % \end{align}
%and a \emph{Linear Evolutionary System} is, 
%\plr{why is this "evolutionary"? It is the thing that we're thinking about evolution of, but that doesn't make it evolutionary.}
%
%Therefore the set of all phenotypically identical (and minimal) systems can be parameterized as, $\mathcal{S}_{\min}(V) = (VAV^{-1}, VB, CV )$,
  %  \begin{align} \label{eq:min_param}
  %    \mathcal{S}(V) := \left\{ \begin{array}{ll} V\dot{\kappa}(t) &= VA V^{-1} \kappa(t) + VB u(t) \\ \phi(t) &= C V^{-1} \kappa(t) \end{array} \right.
  %\end{align}
 % where $V$ is any invertible matrix and it's elements are free parameters. 
%
%Therefore varying $V$ can tweak the relationships between genes within a regulatory network, yet preserve the phenotype. Some gene networks, however, can grown or shrink, perhaps following gene duplications and deletions, and also still preserve their phenotypes. These changes cannot be described by $\mathcal{S}(V)$, but are ecanpuslated by \ref{eqn:equivalence}, below.
%The Kalman decomposition decomposes a system into \emph{reachable} and \emph{observable} components -- that is coefficients that respond to an input and coefficients that produce an observable output. A minimal system's components are both reachable and observable. In this form, it is possible to add components that respond to an input, but do not influence the output, or components that, in principle, influence the output, but do not respond to any inputs. Any system with such components is, by definition, non-minimal, and any system can be modified to include any finite number of extra unreachable and/or unobservable components, without modifying its impulse response. Decomposing the system allows for the easy manipulation of ``superfluous''(but not necessarily expendable) components. After unreachable/unobservable coefficients are added, changing coordinates ``stirs'' the system coefficients such that the previously superfluous coefficients can become essential to system funciton. 
%Whether or not evolution constrains biological systems to be minimal or nearly minimal is an open question. 

\begin{definition}[Phenotypic equivalence of systems]
    Let $(\kappa(t),\phi(t))$ and $(\bar \kappa(t),\bar \phi(t))$ be the solutions to \eqref{eqn:system}
    with coefficient matrices $(A,B,C)$ and $(\bar A,\bar B,\bar C)$ respectively,
    and both $\kappa(0)$ and $\bar \kappa(0)$ are zero. 
    The systems defined by $(A,B,C)$ and $(\bar A,\bar B,\bar C)$ are
    \textbf{phenotypically equivalent} 
    if
    \begin{align*}
        \phi(t) = \bar \phi(t) \qquad \text{for all} \; t \ge 0.
    \end{align*}
    Equivalently, this occurs if and only if
    \begin{align*}
        h(t) = \bar h(t)  \qquad \text{for all} \; t \ge 0,
    \end{align*}
    where $h$ and $\bar h$ are the impulse responses of the two systems.
\end{definition}

One way to find other systems equivalent to a given one
is by change of coordinates:
if $V$ is an invertible matrix, then the systems $(A,B,C)$ and $(VAV^{-1},VB,CV^{-1})$
have the same dynamics because their impulse responses are equal:
  \begin{equation}
    \begin{aligned}
      h(t) &= C e^{A t} B 
      = C V^{-1} V e^{A t} V^{-1} V B \\
      &= C V^{-1} e^{V A V^{-1} t} V B 
      = \bar{C} e^{\bar{A} t} \bar{B}
    \end{aligned}
  \end{equation}
%\begin{align*}
%    CV^{-1}( zI - VAV^{-1})^{-1}VB
%    =
%    CV^{-1}V( zI - A)^{-1}V^{-1}VB
%    =
%    C( zI - A)^{-1}B .
%\end{align*}
However, the converse is not necessarily true: 
systems can have identical impulse responses without being changes of coordinates of each other.
In fact, systems with identical impulse responses can involve interactions between different
numbers of molecular species, and thus be in different dimensions.

We refer to $\calA(\Sys_0)$ as the set of all systems equivalent to $\Sys_0$, regardless of dimension:
\begin{equation} \label{eqn:equivalence}
  \begin{aligned}
    \calA(\Sys_0) 
      &= \left\{
        (A,B,C) : C e^{At} B = C_0 e^{A_0 t} B_0 \; \text{for}\; t \ge 0 
      \right\}  \\
      &= \left\{
        (A,B,C) : C A^r B = C_0 A_0^r B_0 \; \text{for}\; 1 \le r \le n-1 
      \right\} .
  \end{aligned}
\end{equation}
Equivalence of the two characterizations follows from the Cayley-Hamilton theorem.

The set of all systems phenotypically equivalent to a given system $(A,B,C)$ 
is elegantly described using the Kalman decomposition,
which also clarifies the system dynamics.
To motivate this, first note that the input $u(t)$ only directly pushes the system
in directions lying in the span of the columns of $B$.
As a result, different combinations of input can 
move the system in any direction that lies in the \emph{reachable subspace},
which we denote by $\reachable$,
and is defined to be the closure of $\spn(B)$ under applying $A$
(or equivalently, the span of $B, AB, A^2B, \ldots A^{n-1}B$).
Analogously to this, we define
the \emph{observable subspace}, $\mathcal{O}$,
to be the closure of $\spn(C^T)$ under applying $A$.
(Or: $\unobservable$ is the largest $A$-invariant subspace
contained in the null space of $C$;
and $\reachable$ is the largest $A$-invariant subspace contained in the image of $B$.)

If we define
\begin{enumerate}
    \item The columns of $P_\rno$ are an orthonormal basis for $\reachable \cap \unobservable$.
    \item The columns of $P_\ro$ are an orthonormal basis of
        the complement of $\reachable \cap \unobservable$ in $\reachable$.
    \item The columns of $P_\nro$ are an orthonormal basis of
        the complement of $\reachable \cap \unobservable$ in $\unobservable$.
    \item The columns of $P_\nrno$ are an orthonormal basis of
        the remainder of $\R^n$.
\end{enumerate}
If we then define
\begin{align*}
    P &= 
    \left[ \begin{array}{c|c|c|c}
        P_\rno & P_\ro & P_\nro & P_\nrno
    \end{array} \right] ,
\end{align*}
then
\begin{align*}
    P^T P
    &=
    \left[ \begin{array}{c|c|c|c}
        I & 0 & 0 & 0 \\
        \hline
        0 & I & U & 0 \\
        \hline
        0 & V & I & 0 \\
        \hline
        0 & 0 & 0 & I 
    \end{array} \right] .
\end{align*}
\plr{Check this.  Can we get $U=V=0$?}

The following theorem can be found in SOME REFERENCE.

\begin{theorem}[Kalman decomposition] \label{thm:kalman}
        For any system $(A,B,C)$ with corresponding Kalman basis matrix $P$,
        the transformed system $(PAP^{-1},PB,CP^{-1})$  has the following form:
        \begin{align*}
            \widehat A = PAP^{-1}
            &=
            \left[ \begin{array}{cccc}
                A_{\rno} & A_{\rno,\ro} & A_{\rno,\nrno} & A_{\rno,\nro} \\
                0 & A_{\ro} & 0 & A_{\ro,\nro} \\
                0 & 0 & A_{\nrno} & A_{\nrno,\nro} \\
                0 & 0 & 0 & A_{\nro}
            \end{array} \right] ,
        \end{align*}
        and
        \begin{align*}
            \widehat B = PB
            &=
            \left[ \begin{array}{cccc}
                B_{\rno} \\
                B_{\ro} \\
                0 \\
                0 
            \end{array} \right] ,
        \end{align*}
        and
        \begin{align*}
            \widehat C = CP^{-1}
            &=
            \left[ \begin{array}{cccc}
                0 & C_{\ro} & C_{\nrno} & 0 
            \end{array} \right] .
        \end{align*}
        The impulse response of both systems is given by
        \begin{align*}
          h(t) = C_{\ro} e^{A_{\ro} t} B_{\ro} .
        \end{align*}
\end{theorem}

In the latter case, we say that the system is \emph{minimal} 
-- there is no equivalent system with a smaller number of molecular species.
Note that this says that any two equivalent minimal systems
are changes of coordinates of each other.

Since any system can be put into this form,
and once in this form, its impulse response is determined only by 
$C_{\ro}$, $A_{\ro}$, and $B_\ro$,
therefore, the set of all equivalent systems are parameterized by
the dimension $n$,
the choice of basis ($P$),
the remaining submatrices in $\widehat A$, $\widehat B$, and $\widehat C$
(which are unconstrained),
and a invertible transformation of $\spn(P_{\ro})$, which we call $T_\ro$.

\begin{theorem}[Parameterization of equivalent systems]
    Let $(A,B,C)$ be a minimal system.
    \begin{itemize}
        \item[(a)]
            Every equivalent system is of the form given in Theorem \ref{thm:kalman},
            i.e., can be specified by choosing a dimension, $n$;
            submatrices in $\widehat A$, $\widehat B$, and $\widehat C$ 
            except for $A_\ro=A$, $B_\ro=B$, and $C_\ro=C$;
            and choosing an invertible matrix $P$.

        \item[(b)]
            \plr{conjecture:}
            The parameterization is unique
            if $P$ is furthermore chosen so that 
            each $P_x$ other than $P_\ro$ is a projection matrix,
            and that 
            \begin{align*}
                0
                =
                P_x^T P_y
            \end{align*}
            for all $(x,y)$ except $(\ro,\nrno)$.

    \end{itemize} 
\end{theorem}

%Usually, the dimension $n$ and the reference system $\Sys_0$ is implicit and we write only $\calA$.
%Further, we refer to the set of all linear systems with impulse response $h(t)$, regardless of dimension, to be $\allS$,
%  \begin{align}
%    \allS := \bigcup_{n=\min}^{\infty} \calA_n(\Sys_0)
%  \end{align}
It is remarkable to note that even with the relationships between environment, kryptotype, and phenotype constant, and in the minimal dimension, there are still almost always degrees of freedom. These correspond to distinct genetic networks that perform indistinguishable functions. For example, the equivalent systems in Example \ref{ex:all_osc} are minimal, and share common B and C matrices.

It is also remarkable to note that there is no unique triple $(A,B,C)$ for the mapping $h: u \mapsto \phi$. This implies that the gene regulatory network architecture per phenotype/environment pair is never unique -- that is under these assumptions, there is always more than one possible gene regulatory network architecture per phenotype. 
%This set can be precisley defined and completely parameterized using the \emph{Kalman decomposition} (Appendix \ref{apx:kalman}).

For the remainder of the paper, we interpret $\allS$ as the phenotypially neutral landscape, wherein a large population will drift under environmental and selective stasis. Even if the phenotype is constrained and remains constant through evolutionary time, the molecular mechanism underpinning it is not constrained and likely will not be conserved.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection*{Speciation}

%Define reproduction in diploids as first, the recombination of unlinked genes to make gametes, and second, as the averaging of two individual parental gametes to produce an offspring. Assuming parental populations are both phenotypically identical and genetically homogenous within each population, first generation hybrids (F1s) can be computed by averaging the two parental gene networks. Second generation hybrids (F2s) can be computed by first swapping the genes between the two parental gene networks, and next averaging these hybrid gametes.

%Speciation, or the formation of new species, is often a consequence of reprdouctive incompatibility among populations -- usually via hybrid sterility or inviability. To discuss speciaiton we first need to describe how reproduction is modelled.
 %A diploid first generation hybird's ($F_1$'s) genetic regulation is a consequence of its two genomes, as a copy of genes and regulatory sequences from each parent is present.
%\plr{should have a stronger justification for the assertion that $F_1$ is the arithmetic average of the parents than "Thus we say"}
%A diploid organism contains two gene network copies: one from each parent. As such, a diploid's system dynamics is computed by averaging the coefficients of both systems. To reproduce, each organism passes on a recombined haploid gene network to its offspring. Haploid gene networks swap system matrix rows randomly between its own two networks. 
%\plr{I don't think we say that $A$ is a "gene network architecture".}
%Therefore the phenotypic dynamics typical of an $F_{1}$ cross between two allopatric populations will be determined simply by averaging it's two parental genomes. However, in second generation hybrid crosses $F_2$ between allopatric populations, first new haploid systems will be formed by recombination -- in the process shuffling and combining regulatory coefficients from allopatric populations -- and then brought together to form a diploid.

%\begin{align}
%    F_{1}(\tau, \hat{\tau}) &= \frac{ A(\tau) + A(\hat{\tau}) }{2}  .
%   h(t, F_{1}) &= C e^{\left( F_{1}\left( \tau, \hat{\tau} \right) t \right)} B
%\end{align}
%\begin{align*}
% G\left(r, \tau, \hat{\tau}\right) = Q(r) A( \tau ) + \left( I - Q(r) \right) A( \hat{\tau} )
%\end{align*}
%\begin{align}
%    F_{2}(i, j) = \frac{G (i) + G(j)}{2}
%\end{align}

  %\begin{align*}
  %  h\left(t, F_{2}\left( r, r' \right)\right) = C e^{\left( F_{2}\left(r, r' \right) t \right)} B
  %\end{align*}

%Fitness $\fit$ is a function (usually a Guassian) of an organism's weighted phenotypic distance from an optimum,
%  $\fit\left( \widehat{\phi}(t) \right) = \exp \left(- \int_{0}^{t} \frac{\rho(s)}{\beta} \left\lVert \phi(s) - \widehat{\phi}(s) \right\rVert^{2} ds  \right)$
%where $\rho(t)$ is some weighting function and $\beta$ is a parameter.

%We quantitatively describe the degree of incompatibility between two populations $P_{1}$ and $P_{2}$ as
%\begin{align*}
%      \Incompat = \frac{2 \left\langle \fit \left(\phi_{F_{1}}\right) \right\rangle}{\left\langle \fit \left(\phi_{P_{1}}\right) \right\rangle +  \left\langle \fit \left(\phi_{P_{2}}\right) \right\rangle} ,
%\end{align*}
%where angled brackets imply averaging.  \plr{averaging over what? And, this is as others define - cite.}

%\plr{This is not part of the definition of $\mathcal{I}$:}
%\js{should we delete this example ($A(0) \times A(2)$ hybrids)? I like how clean it is -- but I'm not sure it's that important in this context. It's a good proof of principle though.}
%\jss{$F_1$s created by crossing phenotypically equivalent oscillators $A(0)$ and $A(2)$ have a phenotype of $\phi_{F_{1}}(t) = e^{t}$, 
%in contrast to both parents, who have $\phi_{P_{1}}(t) = \phi_{P_{2}}(t) = \sin(t) + \cos(t)$. 
%The hybrid phenotype is significantly different (it does not oscillate and increases infinitely) despite the phenotypic equivalence of the parents.
%%\plr{don't need these to be big equations.}
%%\begin{align*}
%%  \fit \left(\phi_{P_{1}}\right) = \fit \left( \phi_{P_{2}} \right) &= 1 \\
%%  \fit\left(\phi_{F_{1}}\right) &= 0 \\
%%  \mathcal{I} &= 0
%%\end{align*}
%
%%Thus if populations $1$ and $2$ are homogeneous $A(0)$ and $A(2)$, respectively, we say that they are completely incompatible as $\mathcal{I} = 0$.
%
%  \begin{figure}[H]
%    \centering
%    \includegraphics[width=0.5\textwidth, height=0.25\paperheight]{expF1}
%    \caption{$F_1$ hybrid (orange) and parental (blue) phenotypic oscillator dynamics for an $A(0)$ by $A(2)$ cross. The hybrid fails to oscillate and exhibits qualitatively different dynamics.}
%  \end{figure}
%  }
%%     \begin{example}[F1 Reproductive Incompatibility in an Oscillating Gene Network]
%%       DMI examples...
%%       \begin{figure}[H]
%%         \includegraphics[width=0.5\textwidth]{A2_A3_osci_F1_hyb}
%%       \end{figure}
%%     \end{example}
%
%%     \begin{example}[Not all Networks can Host Incompatibilities]
%%       convex sets cant have DMIs
%
%%       \begin{align*}
%%         h(t) = 2 e^{- \theta t}
%%       \end{align*}
%%       Any non-minimal system with rows summing to $\theta$ is PI. Further, these systems are closed under averaging (mating) and row swapping (meiosis), leaving all hybrids optimally fit. The set of gene matrices is affine and therefore convex.  
%%     \end{example}
%
%
%\plri{Missing: a statement about when there are neutral directions, and how many.}
%
%\plr{I think we should first put the section about quantitative drift in, and then the following section that tries to get at real values of parameters.}
%
%
 \begin{example}[All Phenotypically Equivalent Cell Cycle Control Networks] \label{ex:all_osc}
   The set of all two-gene regulatory networks phenotypically equivalent to the cell cycle control network in \ref{ex:oscillator}, where only $A$ can vary, is given by $\Sys (\tau) = (A(\tau), B, C)$, such that, 
    %\begin{align*}
    %  A(\tau) &= \begin{bmatrix} 1 & 0 \\ \tau & 1-\tau \end{bmatrix} \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \frac{\tau}{\tau-1} & \frac{-1}{\tau-1} \end{bmatrix}  \qquad \forall \ \tau \neq 1 %\\
    %\end{align*}
    \begin{align*}
      A(\tau) &= \frac{1}{\tau-1} \begin{bmatrix} \tau & -1 \\ 2 \tau(\tau - 1) + 1 &  -\tau \end{bmatrix} \ \text{for} \ \tau \neq 1
    \end{align*}
    \begin{figure}[H]
    \centering
% Nice tikz!!!
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
  \node (A) at (0,0) {$\kappa_{1}$};
    \node[dashed] (B) at (4,0) {$\kappa_{2}$};
    \node[shape=rectangle] (U) at (2,2) {input};
    \node[shape=rectangle] (y) at (2,-2) {output};
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black, thick}]
    \path [->, sloped] (A) edge[bend left] node {\tiny $2 \tau + (\tau-1)^{-1}$} (B);
    \path [->, sloped] (B) edge[bend left] node {\tiny $-(\tau-1)^{-1}$} (A); 
    \path[->] (U) edge[dashed] node {\tiny $1$} (A);
    \path[->] (U) edge[dashed] node {\tiny $1$} (B);
    \path[->] (A) edge[dashed, bend right] node {\tiny $1$} (y);
\end{scope}
\begin{scope}[>={Stealth[black]},
              every edge/.style={draw=black, thick}]
    \path [->] (A) edge[loop left] node[sloped, anchor=center, above] {\tiny $1 + (\tau-1)^{-1}$} (A);
    \path [->] (B) edge[loop right] node[sloped, anchor=center, above] {\tiny $-1 - (\tau-1)^{-1}$} (B);
\end{scope}

\end{tikzpicture}
      \caption{$\Sys(\tau)$, the set of all phenotype-equivalent cell cycle control networks $\Sys (\tau) = \left\{ \calA_2 : B = [1\ 1]^{T} ,\ C = [1\ 0] \right\}$.}
    \end{figure}
 % \end{example}

 % \begin{example}[External Equivalence does not imply internal equivalence]
   Despite the phenotypic equivalence of all instantiations of $\Sys(\tau)$, the kryptotypes, vary as a function of $\tau$. 
    %Gene-1 dynamics (blue) are equivalent for network architectures $A(0)$ and $A(2)$, however the dynamics of gene-2 (orange) differ with $\tau$.
  \begin{figure}[H]
    \centering
   % \includegraphics[width=0.5\textwidth, height=0.25\paperheight]{osc_A0_A2_both_compare}
    %\caption{Gene-1 (blue) and gene-2 (orange) dynamics for $A(0)$ (top) and $A(2)$ (bottom). Both (top and bottom) gene-1 dynamics are given by $ \kappa_{1} = \sin(t) + \cos(t)$, and gene-2 by $\kappa_{2} = \cos(t) - \sin(t)$ (top) and $\kappa'_{2} = \cos(t) + 3 \sin(t)$ (bottom).}
    \includegraphics[width=0.5\textwidth, height=0.125\paperheight]{figures/osc_kryp_compare}
    \caption{Gene-1 dynamics (blue) for both systems $\Sys(0)$ and $\Sys(2)$ are identical, however, $\Sys(0)$ gene-2 dynamics (orange) differ from $\Sys(2)$ (green). Both gene-1 dynamics are given by $\kappa_{1} = \sin t + \cos t$, and gene-2 by $\kappa_{2} = \cos t - \sin t$ ($\Sys(0)$) and $\kappa'_{2} = \cos t + 3 \sin t$ ($\Sys(2)$).}
  \end{figure}
\end{example}
\begin{example}[Metabolic network] \label{ex:metabolic}
Consider an organism that can metabolize two different sugars (present at logarithmic concentrations $u_{1}$ and $u_{2}$), 
with two enzymes (at log concentrations $\phi_{1}$ and $\phi_{2}$).
Further suppose that the second sugar is prefered,
%and that the organism has a regulatory network that can deploy situation specific metabolic strategy.
and that
depending on $u_{1}$ and $u_{2}$ the organism will synthesize an appropriate $\phi_{1}$ and $\phi_{2}$. 
Furthermore, assume this system contains at least two transcription factors, whose log concentrations are $\kappa_{1}$, $\kappa_{2}$, $\dots \kappa_{n}$.
Minimally such a system may have the architecture,
%\begin{align*}
%    \mathcal{S}_{\min} = \left\{ \begin{array}{ll} \dot{\kappa}(t) &= \begin{bmatrix} 0 & -1 \\ 0 & 0 \end{bmatrix} \begin{bmatrix} \kappa_{1} \\ \kappa_{2} \end{bmatrix} (t) + \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} u_{1} \\ u_{2} \end{bmatrix} (t) \\[11pt]
%    \phi(t) &= \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} \kappa_{1} \\ \kappa_{2} \end{bmatrix} (t) \end{array} \right.
%\end{align*}
  $\Sys_{\min}(U) = (U \left[ \begin{smallmatrix} 0 & -1 \\ 0 & 0 \end{smallmatrix} \right] U^{-1}, U 
    %\left[\begin{smallmatrix} 1 & 0 \\ 0 & 1 \end{smallmatrix}\right]
      ,
     % \left[\begin{smallmatrix} 1 & 0 \\ 0 & 1 \end{smallmatrix}\right]
        U^{-1})$. 
%
%The impulse response of the system is,
%$h(t) = \left[\begin{smallmatrix} 1 & - t \\ 0 & 1 \end{smallmatrix}\right]$.
    We can find alternative equivalent systems by changning coordinates ($U \rightarrow U'$) or, more generally, by applying the Kalman decomposition \ref{apx:kalman}. To illustrate that phenotypic invariance does not require dimensional invariance, we apply the Kalman decomposition to $\Sys_{\min}$ to find 
    %This may happen if a system is co-opted from another, or may be a consequence of gene duplication and deletion. 
  $\Sys(\small D_{1-3},V) \! =  \! \left( \! \begin{array}{ll}
     V \! \left[\begin{smallmatrix} D_{1} & D_{2} \\ 0 & A \end{smallmatrix}\right] \! V^{-1}, V \! \left[\begin{smallmatrix} D_{3} \\ B \end{smallmatrix}\right], \left[\begin{smallmatrix} 0 & C \end{smallmatrix}\right] \! V^{-1} \end{array} \! \right)
$, both of which are in $\allS$
%  \begin{align*}
%    \Sys(X_{1-3},V) = \left( \begin{array}{ll}
%     V \left[\begin{smallmatrix} X_{1} & X_{2} \\ 0 & A_{\min} \end{smallmatrix}\right] V^{-1}, V \left[\begin{smallmatrix} X_{3} \\ B_{\min} \end{smallmatrix}\right], \left[\begin{smallmatrix} 0 & C_{\min} \end{smallmatrix}\right] V^{-1} \end{array} \right)
%    \end{align*}
  ($V$ can be any $4$-dimensional and invertible matrix, $D_{1-3} \in \R^{2 \times 2}$, and $(A,B,C) \in \Sys_{\min}$).
%So for example, some system can be wired as follows, and still be input-output equivalent to the minimal metabolic system $\mathcal{S}_{\min}$:
% \begin{align*}
%   A' &= \begin{bmatrix}
%     1.6923  &  1.5385 &  -2.6154 &  -2 \\
%     0.8462  &  0.7692 &  -1.3077 &  -1 \\
%     1.2692  &  1.1538 &  -1.9615 &  -1.5 \\
%     0.4231  &  0.3846 &  -0.6538 &  -0.5
%   \end{bmatrix} \\
%   B' &= \begin{bmatrix} 4 & 4 \\ 2 & 2 \\ 3 & 3 \\ 1 & 3 \end{bmatrix} \\
%     C' &= \begin{bmatrix}  0.2692  &  0.1538  &  0.0385 &  -0.5 \\
%     -0.4231 &  -0.3846 &   0.6538  &  0.5 \end{bmatrix}
% \end{align*}
%
%Despite the present example consisting of a minimal $2 \times 2$ and a non-minimal $4 \times 4$ system, 
%any $m$-dimensional system can be constructed using this method 
%-- applying a change of coordinates to the Kalman decomposition 
%-- to construct a mechanistically different system with identical phenotypic dynamics. 
%
%When applying the Kalman decomposition to real biological networks, one may have to restrict the free parameters, as physiology and biochemistry might not allow all mathematically possible coefficients. We note that as there are so many degrees of freedom, it may be difficult to infer system function solely from structure. 
\end{example}

\paragraph{Sexual recombination and hybrid incompatibility}
Phenotypically identical yet kryptotypically variant gene networks, when brought together and/or recombined during sexual reproduction, can lead to phenotypic inviability. 

    For instance, the diploid $\{\Sys, \Sys' \}$ has system architecture $\Sys_{\text{diploid}} \! = \! \left(\Sys \! + \! \Sys'\right)\!/2$, the average of its two haploid systems.
    %During meiosis a diploid recombines its two genomes to form a new one (a gamete): $\left(\Sys \! \times \! \Sys' \right) \rightarrow \Sys''$; by randomly swapping matrix rows between two systems (Appendix \ref{apx:recombination}). Then two gametes join to form an offspring (\emph{e.g.} $\{\Sys'',\Sys\} $).

     During meiosis, a diploid recombines its two genomes to form a gamete by randomly swapping rows or columns between its two systems.
  \emph{E.g.} gamete systems $(A'', B'', C'')$, produced by the diploid $\{\Sys, \Sys'\}$, are formed by recombining two systems $\Sys = (A,B,C)$ and $\Sys' = (A', B', C')$  to form $\Sys''$ such that,
  %\begin{align*}
   $A'' = MA + (I-M)A'$, 
   $B'' = MB + (I-M)B'$, and
   $C'' = CM + C'(I-M)$.
 % \end{align*}
  $M$ is a diagonal matrix where each diagonal element is a Bernoulli random variable ($M_{ii} = 0$ or $1$ with equal probability, and $M_{ij}=0$ if $i \neq j$). If systems are different dimensions the smaller system elements can be augmented with $0$s (\emph{e.g.} $\left[ \begin{smallmatrix} A & 0 \\ 0 & 0 \end{smallmatrix} \right], \left[ \begin{smallmatrix} B \\ 0 \end{smallmatrix} \right], \left[ \begin{smallmatrix} C & 0 \end{smallmatrix}\right]$).

Even if two systems yield the same phenotype, their diploid and recombinant systems may not. This is because $\allS$ is not required to be closed under averaging or recombination.

If sexual recombination among systems drawn from $\allS$ yields systems with divergent phenotypes, populations containing significant diversity in $\allS$ can carry genetic load, and isolated populations may fail to produce hybrids with viable phenotypes (Figure \ref{fig:expF1}).

%\paragraph*{Hybrid phenotypic breakdown between oscillators}
%For example, if the two phenotypically equivalent systems $A(0)$ and $A(2)$ from Example \ref{ex:all_osc} hybridize, their offspring's phenotype will fail to oscillate completely. 
  \begin{figure}[H] 
    \centering
    \includegraphics[width=0.5\textwidth, height=0.125\paperheight]{expF1}
    \caption{\textbf{Hybrid phenotypic breakdown} $F_1$ hybrid (orange) and parental (blue) phenotypic cell-cycle control (oscillator) dynamics for an $\Sys(0)$ by $\Sys(2)$ cross from Example \ref{ex:all_osc}. The $F_1$ hybrid
%$\left(A_{F_1}\!\!=\!\!\tfrac{A\!(\!0\!) \! + \! A\!(\!2\!)}{2}\right)$
gene expression fails to oscillate and instead grows exponentialy
($\phi_{F_0}\! = \! \sin t \! + \! \cos t$, however $\phi_{F_1} \! = \! e^t$).
    }
    \label{fig:expF1}
  \end{figure}
%
%\paragraph{Sexual reproduction and speciation}
%A diploid organism contains two gene network copies: one from each parent. As such, a diploid's system dynamics is computed by averaging the coefficients of both systems. To reproduce, each organism passes on a recombined haploid gene network to its offspring. Haploid gene networks swap system matrix rows randomly between its own two networks.
%Therefore the phenotypic dynamics typical of a first generation ($F_{1}$) cross between two allopatric populations will be determined simply by averaging it's two parental genomes. However, in second generation hybrid ($F_2$) crosses, first new haploid systems will be formed by recombination -- in the process shuffling and combining regulatory coefficients from allopatric populations -- and then brought together to form a diploid.
%
%
  \begin{example}[Hybrid Incompatibility in an Oscillating Gene Network] \label{ex:hybrid_osc}
    Here we compare the phenotypes for $F_2$ hybrids formed by crossing oscillators with different values for $\tau$ from \ref{ex:all_osc}, $\Sys(2)$ with $\Sys(2.01)$, $\Sys(2.1)$, and $\Sys(2.5)$.
    Systems have identical phenotypes, however some of the hybrids exhibit markedly different dynamics. 

%        \begin{align*}
%         A(2) = \begin{bmatrix} 2 & -1 \\ 5 & -2 \end{bmatrix} &\qquad A(2.01) = \begin{bmatrix} 1.9901 & -0.9901 \\ 5.0101 & -1.9901 \end{bmatrix} \\
%          A(2.1) = \begin{bmatrix} 1.9091 & -0.9091 \\ 5.1091 & -1.9091 \end{bmatrix} &\qquad A(2.5) = \begin{bmatrix} 1.6667 & -0.6667 \\ 5.6667 & -1.6667 \end{bmatrix}
%     \end{align*} 

%\begin{alignat*}{2}
%      A(2) &= \left[\begin{array}{cc} 2 & -1 \\[6pt] 5 & -2 \end{array}\right] &&\qquad A(2.01) = \left[\begin{array}{cc} 2 -\frac{1}{101} & -1 + \frac{1}{101} \\[6pt] 5 + \frac{1}{99} & -2 + \frac{1}{101} \end{array}\right] \\
%        A(2.1) &= \left[\begin{array}{cc} 2 - \frac{1}{11} & -1 + \frac{1}{11} \\[6pt] 5 + \frac{6}{55} & -2 + \frac{1}{11} \end{array}\right] &&\qquad A(2.5) = \left[\begin{array}{cc} 2 - \frac{1}{3} & -1 + \frac{1}{3} \\[6pt] 5 + \frac{2}{3} & -2 + \frac{1}{3} \end{array}\right]
%\end{alignat*}

%      \begin{figure}[H]
%        \begin{tabular}{cc}
%          \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_1}
%          & \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_2}
%         \\ \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_3}
%          & \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_4}
%          \\ \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_5}
%          & \includegraphics[width=0.2\textwidth]{A2_A3_osci_F2_hyb_6}
%        \end{tabular}
%      \end{figure}

%    \begin{figure}[H]
%      \centering
%      \includegraphics[width=0.5\textwidth]{A2_A2-1_F2s}
%      \caption{F2s from $A(2)$ and $A(2.1)$.}
%    \end{figure}
%      \begin{figure}[H]
%        \begin{tabular}{cc}
%        \includegraphics[width=0.5\textwidth]{F2s-small} \\
%        \includegraphics[width=0.5\textwidth]{F2s} \\
%        \includegraphics[width=0.5\textwidth]{F2s-large}
%        \end{tabular}
%        \caption{F2s from $A(2)$ and $A(2.1)$.}
%      \end{figure}

    \begin{figure}[H] \label{fig:hybs}
  \centering
  \begin{tabular}{ccc}
    \includegraphics[width=0.5\textwidth, height=0.25\paperheight]{F1_comparison} &
    \includegraphics[width=0.5\textwidth, height=0.25\paperheight]{F2s_comparison2}
  \end{tabular}
  \caption{
    $F_1$ (left) and $F_2$ (right) hybrids crossing $\Sys(2)$ with $\Sys(2.01)$ (top), $\Sys(2.1)$ (middle), and $\Sys(2.5)$ (bottom).
    $F_2$ hybrids display more phenotypic divergence than $F_1$s, on average. Further, some $F_2$s completely fail to oscillate, as seen in an $\Sys(2.5)$ $F_2$ (light blue).
    \plri{make axis labels bigger}
  }
\end{figure}

  \begin{figure}[H]
    \centering
    \begin{tabular}{cc}
    \includegraphics[width=0.25\textwidth, height=0.125\paperheight]{figures/f1_quartic2} &
    \includegraphics[width=0.25\textwidth, height=0.125\paperheight]{figures/f2_quad2}
    \end{tabular}
    \caption{(Left) Squared $F_1$ hybrid phenotypes from Figure \ref{fig:hybs} diverge quartically, and (right) $F_2$ hybrid phenotypes diverge quadratically as a function of time in allopatry.}
  \end{figure}
\end{example}
%
%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Systems drift and the accumulation of incompatibilities}
Thus far we have shown that many distinct molecular mechanisms can realize identical phenotypes
and that these mechanisms may fail to produce viable hybrids.
Here we discuss the rate at which evolution shifts molecular mechanisms
and ask whether this process is fast enough to be a significant driver of speciation.
To do so, we explore a general quantitative genetic model in which a population drifts stochastically
near a set of equivalent and optimal systems. We work with a population of effective size $N_e$. 

At any given time, there will be a range of regulatory coefficients present in the population
due to segregating genetic variants.
Over many generations, even if selective pressures do not change,
this range of networks will shift 
as recombination, mutation, and demographic noise create new alleles and shift allele frequencies.
%How much variation do we expect to find within a population?
%Is this range limited by available variation or kept in check by selection?
%How fast will a population explore the space of equivalent networks?
%In this section we explore informally a general model for this situation,
%in which a population drifts stochastically near a set of equivalent, optimal systems.
%We work with a population of effective size $N_e$.

Suppose that a set $x$ of coefficients that determine a system (this is $\Sys$ above),
produce a phenotype $\Phi(x)$ (the time course of $\phi(t)$).
There is an optimal phenotype $\optph$,
and a set $\optx$ of ``optimal'' coefficients that produce this phenotype.
Fitness depends on distance to the optimal phenotype --
we will write the ``distance'' between phenotypes $\phi$ and $\psi$ as $\dph(\phi, \psi)$,
measured so that the fitness of an organism with coefficents $x$ is $\fitx(x) = \exp(-\dph(\Phi(x),\optph)^2)$. 
We will assume that the map $\Phi$ is smooth
and that the optimal set $\optx$ is locally isomorphic to $\R^m$.
\plr{say that better}

%\paragraph{Offspring.}
%\js{Not sure if this section is redundant, since reproduction is described above for the LTI model.}
%Individuals are diploid; we assume that each haploid genome determines a set of coefficients,
%and the individual's coefficients are the average of her two haploid values (no dominance).
%This implies that the diploid population variance, $\sigma^2$, is one-half the haploid variance.
%Each new gamete is produced from the parent's two haploid copies;
%for simplicity we assume that the gamete inherits a random choice of one of the two parental copies,
%and so $\sigma$ remains constant, up to a $1/N_e$ term.
%A more general model including segregation variance \citep{barton_infinitesimal}
%would result in the same qualitative conclusions.
%\plri{but put this in the appendix?}

\paragraph{System drift}
% plr how fast does it drift
If the regulatory coefficient population variation
has standard deviation $\sigma$,
since subsequent generations resample from this diversity,
the population mean coefficient will move a random distance of size $\sigma/\sqrt{N_e}$ per generation,
simply because this is the the standard deviation of the mean of a random sample \citep{lande_drift}.
% (This could be taken as a definition of $N_e$.)
Selection will tend to restrain this motion,
but mean movement along the optimal set $\optx$ is unconstrained.
% (although perhaps complicated by recombination load \citep{recomb_load})
The amount of variance in particular directions in coefficient space 
depend on constraints imposed by selection and 
the covariance between genetic variation between different coefficients (the $G$ matrix \citep{G_matrix}).
% covariance which may arise due to functional constraints and/or statistical linkage.
% There may well be functional constraints -- but these are not sufficiently well-known to say anything general about.
%For instance,
%if the variation is due to \textit{cis}-regulatory variants,
%the genetic basis of each \emph{row} of $A$ likely lies within a few kilobases of tightly linked sequence,
%across which a population may carry only a few common haplotypes.
%However, covariance due to transiently assembled haplotypes is not expected to be stable over long periods of time --
%a common \textit{cis}-regulatory haplotype of transcription factor $k$ with particularly strong binding to both $i$ and $j$
%(leading to positive covariance between $A_{ik}$ and $A_{jk}$)
%is no more likely to appear than one with strong binding to $i$ but particularly weak binding to $j$ (negative covariance).
%(Such transient covariances may well increase the variance of the per-generation change in network mean, however \citep{barton_linkage}.)

% It therefore seems reasonable to coarsely model the time evolution of population variation in regulatory coefficients as 
% (a) a ``cloud'' of width X about the population mean, 
% which (b) moves as an unbiased Brownian motion through the set of network coefficients that give the optimal phenotype.
% In fact, the population mean will not produce exactly the optimal phenotype,
% but it will be convenient to refer to this closest point on the optimal set as ``the population mean''.

%To obtain a general quantitative picture, we need to know 
We denote
$\sigma_N$ and $\sigma_S$, the standard deviations of coefficient variation along and perpendicular to $\optx$ respectively,
and $\gamma$, the scale on which phenotype changes moving away from $\optx$.
Concretely, $\gamma$ is the inverse of the derivative of $\dph(\Phi(x+u z), \Phi(x))$ 
with respect to $u$ for $x \in \optx$ and $z$ perpendicular to the tangent space at $x$.
With these parameters, a typical individual will have a fitness of around $\exp(-(\sigma_S/\gamma)^2)$.

\paragraph{Hybridization}
The means of two allopatric populations separated for $T$ generations
will be a distance of order $2\sigma_N \sqrt{T/N_e}$ apart along $\optx$.
A population of $F_1$ hybrids has one haploid genome from each,
whose coefficients are averaged,
and so will have mean system coefficients at the midpoint between their means,
and variance equal to $\sigma^2$. 
Each $F_2$ hybrid will be homozygous for one parental allele on averge at half of the loci in the genome,
so the distribution of $F_2$s will have mean at the average of the two populations,
as before,
but variance equal to $\sigma^2 + z^2/2$, where $z$ is the distance between the parental populations. 
These are depicted in figure \ref{fig:conceptual_fig}.

\begin{figure}[H]
\centering
\includegraphics{figures/conceptual_fig}
\caption{
    \label{fig:conceptual_fig}
    A conceptual figure of the fitness consequences of hybridization:
    axes represent system coefficients (i.e., entries of $A$);
    the line of optimal system coefficients is down in black;
    dotted lines give phenotypic distances to the optimum.
    Two pairs of parental populations are shown in black, along the optimum;
    a hypothetical population of $F_1$s are shown for each in red,
    and the distribution of one type of $F_2$ is shown in purple
    (other types of $F_2$ are not shown).
    Solid lines depict the distance of the $F_2$ to optimum.
    \plri{Should show all types of F2? would be messy.}
}
\end{figure}

\plri{improve figure by putting labels on from the following}
Suppose that two populations have drifted independently to differ by $z$,
and that $z$ is of the same order as $\sigma$ but is smaller than $\gamma$.
The mean $F_1$ is the average of the parental means,
and since the first-order terms in the Taylor series vanish,
has phenotype differing from the optimum by a distance of order $\|z\|^2$ 
(see appendix \ref{apx:away_from_opt}).
The mean $F_2$ is the same,
but the standard deviation is of order $z$,
so that up to lower order terms, 
while the typical fitness of an individual in the original population is
$\fit_0 = \exp(-(\sigma_s/\gamma)^2)$;
of an $F_1$ is
$\fit_1/\fit_0 = \exp(-(c_1 \sigma_N^2 T/N_e)^2)$;
and of an $F_2$ is
$\fit_2/\fit_0 = \exp(- T/(N_e\gamma^2))$.

Note that this follows directly from the fact that $F_1$ and $F_2$ hybrid phenotypes diverge from $F_0$ phenotypes, linearly and inverse-quadratically, with respect to time (more precisely $T/N_e$). As such, removing assumptions about the form of the fitness function, this model still predicts hybrid $F_2$ phenotypes to diverge much faster than $F_1$s, initially.

%\subsection*{Parameter estimates for real systems}
%\js{I think we should move this section?}
%To translate these results into real predictions, we need to know
%the strength of stabilizing selection on the phenotype,
%and the amount (and structure) of heritable variation in the genotype.
%These are known at best only roughly \citep{felsenstein1988phylogenies},
%so we aim for order-of-magnitude estimates.

%% amount of heritable variation
%We quantify (roughly) the amount of heritable variation
%by $\sigma^2$, the genetic variance present in a population in a typical entry of $\Sys$.
%The coefficient $A_{ij}$ measures how much the rate of net production of $i$ changes
%per change in concentration of $j$.
%It is generally thought that regulatory sequence change contributes much more to inter- and intraspecific variation
%than does coding sequence change affecting molecular structure \citep{schmidt2010vertebrate}.
%In the context of transcription factor networks this may be affected 
%not only by the binding strength of molecule $j$ to the promoter region of gene $i$
%but also the effects of other transcription factors (e.g., cooperativity)
%and local chromatin accessibility \citep{stefflova2013cooperativity}.
%For this reason, 
%the mutational target size for variation in $A_{ij}$ may be much larger than the dozens of base pairs
%typically implicated in the handful of binding sites for transcription factor $j$ of a typical promoter region,
%and single variants may affect many entries of $\Sys$ simultaneously.
%% (Recall that although these are best modeled through nonlinear terms,
%% by linearizing we essentially consider first-order effects.)
%On the other hand, a diverse set of buffering mechanisms are thought to contribute to phenotypic stability
%in the presence of substantial molecular noise \citep{canalization,buffering},
%suggesting that substantial variation in the micro-scale dynamics we consider here
%may be necessary to produce relevant phenotypic effects downstream.
%\plr{replace "micro-scale" with sthg else or discuss earlier}

%% empirical data on sigma
%The amount and structure of this standing variation is established over long time scales
%by many factors, including
%mutation-selection balance, 
%shifts in the phenotypic optimum,
%and/or spatial variation in the optimum \citep{hansen1996translating}.
%Quantitative genetics models of mutation-selection balance 
%predict precise levels and structure of standing variation \citep{kimura_mutsel,lande_mutsel,lande1981models},
%but it is unclear how well these predictions match reality \citep{johnson_barton}
%and how much they are expected to change over time \citep{arnold_changing_G}.
%However, empirical work allows us to estimate at least the rough magnitude of variation.
%Differences in $A_{ij}$ due to a sequence change are hard to measure,
%but variation in both transcription factor binding site occupancy
%and expression levels (e.g., cis-eQTL) have been measured in various systems.
%However, variation in binding site occupancy may overestimate variation in $\Sys$,
%since it does not capture buffering effects (if for instance only one site of many needs be occupied for transcription to begin),
%and variation in expression levels measures changes in steady-state concentration (our $\kappa_i$) rather than the \emph{rate} of change.
%%Nonetheless,
%%\citet{kasowski2010variation} found differential occupancy in 7.5\%
%%of binding sites of a transcription factor (p65) between human individuals.
%%\citet{verlaan2009targeted} showed that cis-regulatory variation
%%accounts for around 2--6\% of expression variation in human blood-derived primary cells,
%%while \citep{lappalainen2013transcriptome} found that human population variation 
%%explained about 3\% of expression variation.
%%\plr{Get some data from at least one other species in here!}
%%Taken together, this suggests that variation in the entries of $\Sys$
%%may be on the order of 1\% between individuals of a population --
%%doubtless varying substantially between species and between genes.
%%
%Given the empirical data on transcription factor binding and gene expression
%intrapopulation variation \citet{kasowski2010variation, verlaan2009targetedm lappalainen2013transcriptome}, we conservatively estimate that variation in the regulatory coefficients in $\Sys$ may be on the order of 1\% between individuals of a population -- 
%doubtless varying substantially between species and between genes.
%
%%% argument for strength of selection
%%It seems certain that selection in most species is not so strong that intra-population variation
%%is strongly deleterious,
%%so that if $\beta$ is the typical scale on which selection acts,
%%then $\beta > \sigma$.  
%%However,
%%a range of studies \plr{find them} have found evidence for weak stabilizing selection
%%on regulatory SNPs and cis-eQTL.
%For instance, 
%\citet{maria_and_sergey} \plr{(others?)} found evidence that large-effect regulatory mutations are weakly selected against in Drosophila.
%This suggests that 
%the strength of selection on phenotype is sufficient to weakly constrain regulatory variation,
%so that perhaps $\sigma$ and $\beta$ are relatively close.
%This is as would be expected if available variation is held in check by mutation--selection balance
%rather than genetic drift.
%A conservative estimate would be that $\beta = 5 \sigma$;
%taking $\sigma=.01$ as above, this suggests that changes in phenotype of 5\% are sufficient
%to effect a noticeable drop in fitness.
%\plr{BUT $\sigma$ IS VARIATION IN $A$ NOT PHENOTYPE}
%
%We have guessed that within a population, 
%the entries of $\Sys$ vary by around 1\%, 
%at least for networks whose function is strongly constrained.
%
%
\paragraph{Speciation rates under neutrality}
%For cases where system structures and $\gamma$ can be inferred,
%specific speciation rates can be estimated.
%For other situations we offer a back of the envelope calculation.
%
%Consider a population that is distributed on $\mathcal{X}$ such that the magnitude of phenotypically
%divergent $\sigma_S$ and neutral $\sigma_N$ diversity are constrained by selection;
%$\sigma_S$ directly, such that $\sigma_S = \gamma$, and $\sigma_N$ indirectly via recombination load.
%Two reproductively isolated populations will, on average, be a distance of $2 \sigma_N \sqrt{T/N_e}$.
%If we assume that $\sigma_N$ is constrained by a function of $\sigma_S$,
%neutral movement along $\mathcal{X}$ pushes hybrids off of the manifold by $\sigma_S$ per $\sigma_N$,
%Lastly, if fitness is Gaussian: $\fit_2 = \exp\left(- d(x, x')^2/\beta^2\right)$,
%and we assume that the strength of selection is only several multiples of the segregating divergent diversity,
%such that $\sigma_S = c \beta$, we can simplify the expression estimating $F_2$ hybrid fitness drops
%to be,
%
%
%$F_2$s between allopatric populations will suffer an average fitness drop relative to their parents of,
%  \begin{align}
%    \exp\left(-\left( \frac{2\sigma_{N}}{\beta}\sqrt{\frac{T}{N_e}} \right)^{2} \right) .
%  \end{align}

%If the strength of selection is only a few multiples $\xi_1$ of the standing phenotypic diversity within a population $\sigma_S$, such that $\beta = \xi_1 \sigma_S$, and recombination load constrains the standing phenotype-neutral diversity $\sigma_N$ to be only a few multiples $\xi_2$ of $\sigma_S$, then $F_2$ fitness drop will be,
%  \begin{align}
%    \exp\left(- \xi^{2} \frac{T}{N_e} \right)
%  \end{align}
%  where $\xi := 2\xi_2/\xi_1$.
  If we assume that perpendicular variation segregating within a population is constrained by selection such that $\sigma_S/\gamma = \xi$, and that neutral variation is on the order of perpendicular variation, such that $\sigma_N = \sigma_S$, then the typical distance between two individuals drawn from separate allopatric populations will be $z = 2 \sigma_N \sqrt{T/N_e}$. We will expect a drop in hybrid fitness to be,
  \begin{align}
  \fit_2/\fit_0 = \exp \left(- 4\xi^2 \frac{T}{N_e} \right) .
  \end{align}
  Hybrid fitness depression will be significant when $z > \gamma$. 
  If $\xi$ is in $[\sfrac{1}{5},1]$, speciation will occur on the order of $N_e$ generations, and possibly much faster. Note, however, that if intrapopulation variation is very small such that $\sigma_S \ll \gamma$, speciation rates will be slower.
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\section*{Discussion}
%
%\jss{Discussion guidelines:
%\begin{itemize}
%    \item Why is this important/useful?
%    \item What are the assumptions and shortcomings of the research?
%    \item Compare to other studies in the literature. 
%    \item Future directions. 
%    \item Wild speculations?
%    \item Conclusion and overall impact. 
%\end{itemize}}
%
The complexity of biological systems has limited our understanding of their function and evolution. Above we outline an approach, a first step, towards untangling this complexity in reference to function and evolution. This methodology borrows successfully applied tools from engineering and aims to synthesize these with the concepts and tools of molecular and evolutionary biology. 

Theoretical models in evolution and population genetics often lack the molecular details of physiology or of the genotype-phenotype map. 
Here, we offer a tractable and simple model which includes these missing features. 
Further, we provide, in clear mathematical language, an analytical description of phenomena hitherto discussed verbally and conceptually 
(phenogenetic drift \citep{weiss2000phenogenetic}, developmental systems drift \citep{true2001developmental}, biological degeneracy \citep{edelman2001degeneracy}, \emph{etc.}). 
The tractability and relative simplicity of this exposition enables the interested biologist to work out by hand, 
if desired, 
the dynamics of a genetic system, as well as perturbations to the system -- an attribute not likely to be found in less tractable models and simulations.

We have suggested an interpretation of system identification: to see it as an evolutionarily neutral manifold, and not simply a computational nuisance. 
We have demonstrated a method to analytically determine the set of all phenotypically invariant gene networks; 
by a simple change of coordinates in the minimal configuration, or more generally by applying the Kalman decomposition in higher dimensions. 
%Further, we emphasize that evolution proceeds through this high dimensional space as stochastic coordinate transformation, constrained by sexual reproduction and selection. 
This set is explored over evolutionary time when phenotype is conserved, and can lead to a diverse set of consequences, 
including the accumulation of Dobzhansky-Muller incompatibilities. 
\plr{check original Bateson/DM papers to see if this accords with those defns}\js{I read through Orr's review of those papers, which included excerpts. It seems like the DMI definition is very general and this accords.}
We emphasize that these incompatibilities are a consequence of recombining different, yet functionally equivalent, mechanisms.

Furthermore, using a quantitative genetic approach, we estimated that a genetically variable population will drift in neutral system space 
at a rate determined by its intra-population variation and its effective population size. 
Because mechanistically distinct yet phenotypically equivalent biological systems can fail to produce viable hybrids, we predict allopatric populations to accumulate genetic incompatibilities 
at a rate on the order of $N_{e}$ if intrapopulation regulatory variation is constrained by selection.
Additionally we see second-generation hybrid fitness plummet much faster than that of first-generation hybrids. 
\plr{refer to Turelli here}
%This is a consequence of combining our mechanistic model with a quantitative genetic one: 
%we observe that $F_{1}$ phenotypes diverge quartically, and $F_{2}$ phenotypes quadratically, with evolutionary time. 
%\plr{awkward phrasing}
This result is also consistent with Haldane's rule; that if only one hybrid sex is inviable or sterile it is likely the heterogametic sex. 
The consistency comes from gene networks localized to the sex chromosomes functioning as an $F_{2}$ hybrid cross within a diploid $F_{1}$ heterogamete as there is only one sex chromosome.
  
%We also suggest that gene networks may not always use their components parsimoniously 
%as network size tends to ratchet up in the absence of strong selection against extra parts. 
%\plr{probably shouldn't claim this is "unexplored"} \js{I meant unexplored within this paper.Changed wording. Does that work?}
%Although we leave this question unexplored, this phenomena may lead to insights on evolvability and developmental innovation. 
Lastly, we show that hybrid gene networks, under neutral processes, break down as function of genetic distance, and may, in part, explain broad patterns of reproductive isolation among diverse phyla \citep{roux2016shedding}.

%\plr{this paragraph isn't very clear} \js{Should I delete it? I guess it's sort of just a vague ``yeah we know this method has shortcomings''.}
%As Richard Levins opined, models in population biology face a trade-off among precision, realism, and generality \citep{levins1966strategy}. As Levins expects, any tractable and general model, such as the present one under discussion, will have limitations. Most notable is linearity. It is often stated that life is not linear. This is often true, however, many of the ideas developed here should be generalizable to nonlinear cases (multi-linear systems, say). Further, we see this as a necessary first step in the direction of more life-like nonlinear evolutionary systems theory. Depending on an actual biological system's particularities, its (potential) non-linearity, may buffer or exacerbate effects elucidated in this paper, such as the acquisition of Dobzansky-Muller incompatibilities.

%This theoretical framework can easily be applied to other interesting questions in evolutionary biology not tackled presently: such as the evolution of linkage, the necessity of network complexity (does evolution tend towards Rube Goldberg or parsimonious network organization?), evolvability, structure/function inference, and intra-population context dependency of mutational effects, as well as many others.

%\jss{literature comparison -- I think we should delete}
%
%Over the last several years, several different computational approaches have been applied to study reproductive incompatibility and speciation. \citet{tulchinsky} simulated the evolution of a transcription factor and its binding site using a thermodynamic model. Their simulations suggest that the language by which a transcription factor recognizes its binding site can change, and potentially lead to hybrid incompatibility when allopatric populations employ divergent readout languages. This study, despite looking at gene regulation, does not analyze overall gene network architecture -- as we do here -- it only looks at the expression level of a single gene. Furthermore, they report reproductive isolation primarily following directional selection for a change in expression levels in each allopatric population; the evidence for reproductive isolation following balancing selection is much weaker. Johnson and Porter 2000 did not observe any hybrid fitness declines under stabilizing selection -- only under directional selection. 
%\plr{citations:}
%Khatari et al, Tulchinsky et al, and Porter et al, all study hybrid incompatibility from a transcription factor/binding site interaction perspective, not from an overall network architecture perspective. Palmer and Feldman only see hybrid incompatibility in constant environments if the parental populations are relatively poorly adapted initially. Otherwise hybrids between two allopatric populations have fairly high fitnesses.  

\section*{Acknowledgements}
We would like to thank Sergey Nuzhdin, Stevan Arnold, Erik Lundgren, and Hossein Asgharian for valuable discussion.

\bibliographystyle{plainnat}
\bibliography{krefs}
%\end{multicols}

\normalsize

\section*{Examples}
 
 

\appendix

\section{Kalman Decomposition} \label{apx:kalman}
\begin{definition}[Phenotypic equivalence of systems]
    Let $(\kappa(t),\phi(t))$ and $(\bar \kappa(t),\bar \phi(t))$ be the solutions to \eqref{eqn:lti_system}
    with coefficient matrices $(A,B,C)$ and $(\bar A,\bar B,\bar C)$ respectively,
    and both $\kappa(0)$ and $\bar \kappa(0)$ are zero. 
    The systems defined by $(A,B,C)$ and $(\bar A,\bar B,\bar C)$ are
    \textbf{phenotypically equivalent} 
    if
    \begin{align*}
        \phi(t) = \bar \phi(t) \qquad \text{for all} \; t \ge 0.
    \end{align*}
    Equivalently, this occurs if and only if
    \begin{align*}
        h(t) = \bar h(t)  \qquad \text{for all} \; t \ge 0,
    \end{align*}
    where $h$ and $\bar h$ are the impulse responses of the two systems.
\end{definition}

One way to find other systems equivalent to a given one
is by change of coordinates (``algebraic equivalence''):
if $V$ is an invertible matrix, then the systems $(A,B,C)$ and $(VAV^{-1},VB,CV^{-1})$
have the same dynamics because their transfer functions are equal:
\begin{align*}
    CV^{-1}( zI - VAV^{-1})^{-1}VB
    =
    CV^{-1}V( zI - A)^{-1}V^{-1}VB
    =
    C( zI - A)^{-1}B .
\end{align*}
However, the converse is not necessarily true: 
systems can have identical transfer functions without being changes of coordinates of each other.
In fact, systems with identical transfer functions can involve interactions between different
numbers of molecular species.

The set of all systems phenotypically equivalent to a given system $(A,B,C)$ 
is elegantly described using the Kalman decomposition,
which also clarifies the system dynamics? tells us a lot about how it works? \plr{or something}
To motivate this, first note that the input $u(t)$ only directly pushes the system
in directions lying in the span of the columns of $B$.
As a result, different combinations of input can 
move the system in any direction that lies in the \emph{reachable subspace},
which we denote by $\reachable$,
and is defined to be the closure of $\spn(B)$ under applying $A$
(or equivalently, the span of $B, AB, A^2B, \ldots A^{n-1}B$).
Analogously to this, we define
the \emph{observable subspace}, $\mathcal{O}$,
to be the closure of $\spn(C^T)$ under applying $A$.
(Or: $\unobservable$ is the largest $A$-invariant subspace
contained in the null space of $C$;
and $\reachable$ is the largest $A$-invariant subspace contained in the image of $B$.)

If we define
\begin{enumerate}
    \item The columns of $P_\rno$ are an orthonormal basis for $\reachable \cap \unobservable$.
    \item The columns of $P_\ro$ are an orthonormal basis of
        the complement of $\reachable \cap \unobservable$ in $\reachable$.
    \item The columns of $P_\nro$ are an orthonormal basis of
        the complement of $\reachable \cap \unobservable$ in $\unobservable$.
    \item The columns of $P_\nrno$ are an orthonormal basis of
        the remainder of $\R^n$.
\end{enumerate}
If we then define
\begin{align*}
    P &= 
    \left[ \begin{array}{c|c|c|c}
        P_\rno & P_\ro & P_\nro & P_\nrno
    \end{array} \right] ,
\end{align*}
then
\begin{align*}
    P^T P
    &=
    \left[ \begin{array}{c|c|c|c}
        I & 0 & 0 & 0 \\
        \hline
        0 & I & U & 0 \\
        \hline
        0 & V & I & 0 \\
        \hline
        0 & 0 & 0 & I 
    \end{array} \right] .
\end{align*}
\plr{Check this.  Can we get $U=V=0$?}

The following theorem can be found in SOME REFERENCE.

\begin{theorem}[Kalman decomposition] \label{thm:kalman}
        For any system $(A,B,C)$ with corresponding Kalman basis matrix $P$,
        the transformed system $(PAP^{-1},PB,CP^{-1})$  has the following form:
        \begin{align*}
            \widehat A = PAP^{-1}
            &=
            \left[ \begin{array}{cccc}
                A_{\rno} & A_{\rno,\ro} & A_{\rno,\nrno} & A_{\rno,\nro} \\
                0 & A_{\ro} & 0 & A_{\ro,\nro} \\
                0 & 0 & A_{\nrno} & A_{\nrno,\nro} \\
                0 & 0 & 0 & A_{\nro}
            \end{array} \right] ,
        \end{align*}
        and
        \begin{align*}
            \widehat B = PB
            &=
            \left[ \begin{array}{cccc}
                B_{\rno} \\
                B_{\ro} \\
                0 \\
                0 
            \end{array} \right] ,
        \end{align*}
        and
        \begin{align*}
            \widehat C = CP^{-1}
            &=
            \left[ \begin{array}{cccc}
                0 & C_{\ro} & C_{\nrno} & 0 
            \end{array} \right] .
        \end{align*}
        The transfer function of both systems is given by
        \begin{align*}
            H(z) = C_{\ro} ( zI - A_{\ro} )^{-1} B_{\ro} .
        \end{align*}
\end{theorem}

In the latter case, we say that the system is \emph{minimal} 
-- there is no equivalent system with a smaller number of species.
Note that this says that any two equivalent minimal systems
are changes of basis of each other.

Since any system can be put into this form,
and once in this form, its transfer function is determined only by 
$C_{\ro}$, $A_{\ro}$, and $B_\ro$,
therefore, the set of all equivalent systems are parameterized by
the dimension $n$,
the choice of basis ($P$),
the remaining submatrices in $\widehat A$, $\widehat B$, and $\widehat C$
(which are unconstrained),
and a invertible transformation of $\spn(P_{\ro})$, which we call $T_\ro$.

\begin{theorem}[Parameterization of equivalent systems]
    Let $(A,B,C)$ be a minimal system.
    \begin{itemize}
        \item[(a)]
            Every equivalent system is of the form given in Theorem \ref{thm:kalman},
            i.e., can be specified by choosing a dimension, $n$;
            submatrices in $\widehat A$, $\widehat B$, and $\widehat C$ 
            except for $A_\ro=A$, $B_\ro=B$, and $C_\ro=C$;
            and choosing an invertible matrix $P$.

        \item[(b)]
            \plr{conjecture:}
            The parameterization is unique
            if $P$ is furthermore chosen so that 
            each $P_x$ other than $P_\ro$ is a projection matrix,
            and that 
            \begin{align*}
                0
                =
                P_x^T P_y
            \end{align*}
            for all $(x,y)$ except $(\ro,\nrno)$.

    \end{itemize} 
\end{theorem}

\plr{Another way of saying it: pick the $\reachable$ and $\unobservable$ subspaces,
that must intersect in something of the minimal dimension;
then let $P$ be the appropriate basis?}

In some situations we may be interested in only ``network rewiring'',
where $A$ changes while $B$ and $C$ do not.
For instance, 
if all non-regulatory functions of each molecule are strongly constrained,
then $C$ cannot change.
Likewise, if responses of each molecule to the external inputs are not changed by evolution,
then $B$ does not change.


\subsection{Neutral directions from the Kalman decomposition}

The Kalman decomposition above says that any system $(A,B,C)$ can be decomposed into
$(P, \hat A, \hat B, \hat C)$ so that
$$\begin{aligned}
    A &= P^{-1} \hat A P  \\
    B &= P^{-1} \hat B  \\
    C &= \hat C P ,
\end{aligned}$$
and we know precisely how we can change these to preserve the transfer function:
\begin{enumerate}
    \item $P \to P + \epsilon Q$ as long as the result is still invertible,
    \item $\hat A \to A + \epsilon X$ as long as $X$ is zero in the correct places,
    \item $\hat B \to B + \epsilon Y$ as long as $Y$ is zero in the correct places,
    \item $\hat C \to C + \epsilon Y$ as long as $Z$ is zero in the correct places.
\end{enumerate}
By taking $\epsilon \to 0$, these tell us the local directions we can move a system $(A,B,C)$ in.
All statements below are up to first order in $\epsilon$,
omitting terms of order $\epsilon^2$.

First, since $(P + \epsilon Q)^{-1} = P^{-1} + \epsilon P^{-1} Q P^{-1}$,
modifying $P \to P + \epsilon Q$ changes
$$\begin{aligned}
    A 
        &\to A + \epsilon P^{-1} \hat A Q - \epsilon P^{-1} Q P^{-1} \hat A P \\
        &= A + \epsilon \left(A P^{-1} Q - P^{-1} Q A\right) , \\
    B
        &\to B - \epsilon P^{-1} Q B \\
    C
        &\to C + \epsilon C P^{-1} Q .
\end{aligned}$$
Since $P$ is invertible and $Q$ can be anything (if $\epsilon$ is small enough),
this allows changes in the direction of an arbitrary $W$:
$$\begin{aligned}
    A 
        &= A + \epsilon \left(A W - W A\right) , \\
    B
        &\to B - \epsilon W B \\
    C
        &\to C + \epsilon C W .
\end{aligned}$$

Then, $\hat A \to A + \epsilon X$  does
$$\begin{aligned}
    A \to A + \epsilon P^{-1} X P 
\end{aligned}$$
and $\hat B \to B + \epsilon Y$ does
$$\begin{aligned}
    B \to B + \epsilon P^{-1} Y
\end{aligned}$$
and $\hat C \to C + \epsilon Z$ does
$$\begin{aligned}
    C \to C + \epsilon Z P .
\end{aligned}$$
These degrees of freedom look like they depend on $P$, 
which is not unique,
but for any two choices of $P$ there are corresponding choices of $X$
that give the same actual change in $A$ (and likewise for $Y$ and $Z$).


Therefore, this gives us an upper bound on the number of degrees of freedom,
in terms of the dimensions of the blocks in the Kalman decomposition ($n_\ro$ etc)
and the dimensions of $B$ and $C$ ($n_B$ and $n_C$ respectively):
namely, for $W$, $X$, $Y$, and $Z$ respectively:
$$\begin{aligned}
    n^2 
    + (n_{\rno} + n_\ro n_\nro + n_\nrno(n_\nrno + n_\nro) + n_\nro^2)
    + n_B n_\rno
    + n_C n_\nrno .
\end{aligned}$$
However, some of these may be redundant.
For instance, changing $P$ in the direction of 
a $Q$ that satisfies both $A P^{-1} Q = P^{-1} Q A$ and $C P^{-1} Q = 0$
is equivalent to changing $B$ by $Y = QB$.

\section{Meiotic recombination in linear systems}\label{apx:recombination}

  Recombination is performed by taking two analogous system components from $\Sys$ and $\Sys'$ and randomly swapping rows or columns.
  \emph{E.g.} gamete systems $(A'', B'', C'')$, produced by the diploid $\{\Sys, \Sys'\}$, are formed by recombining (randomly swapping rows or columns) between two, possibly distinct, systems $\Sys = (A,B,C)$ and $\Sys' = (A', B', C')$ such that,
  \begin{align*}
    \Sys'' = \left( \begin{array}{ll}
    A'' &= MA + (I-M)A' , \\
    B'' &= MB + (I-M)B' , \\
    C'' &= CM + C'(I-M)
    \end{array} \right)
  \end{align*}
  where $M$ is a diagonal matrix where each diagonal element is a Bernoulli random variable ($M_{ii} = 0$ or $1$ with equal probability, and $M_{ij}=0$ if $i \neq j$). If systems are different dimensions the smaller system elements can be augmented with $0$s (\emph{e.g.} $\left[ \begin{smallmatrix} A & 0 \\ 0 & 0 \end{smallmatrix} \right], \left[ \begin{smallmatrix} B \\ 0 \end{smallmatrix} \right], \left[ \begin{smallmatrix} C & 0 \end{smallmatrix}\right]$).

\section{Genetic drift with a multivariate trait}
\label{ss:quant_gen}

For completeness, we provide a brief argument of how the population mean
moves under genetic drift
with a quantitative genetics model,
as in \citet{lande1981models} or \citet{hansen1996translating}.
These ignore details of the underlying genetic basis,
but developing a more accurate model is beyond the scope of this paper.

\paragraph{Completing the square}
First note that 
\begin{align*}
    (x-y)^T A (x-y)
    &=
    x^T A \left( x - 2y \right) + y^T A y ,
\end{align*}
and so
\begin{align*}
    (x-y)^T A (x-y) + x^T B x
    &=
    x^T (A + B) \left( x - 2 (A + B)^{-1} A y \right) + y^T A y \\
    &=
    \left( x - (A + B)^{-1} A y \right)^T
    (A + B)
    \left( x - (A + B)^{-1} A y \right)
    + \text{(terms that don't depend on $x$)} .
\end{align*}
Therefore, if $f(x;\Sigma,y)$ is the density of a Gaussian with mean $y$ and covariance matrix $\Sigma$
then substituting $A=\Sigma^{-1}$ and $B=U^{-1}$ above,
\begin{align*}
    \frac{ f(x;\Sigma,y) f(x;U,0) }{\int_x f(z;\Sigma,y) f(z;U,0) dz}
    &=
    f(x; (\Sigma^{-1} + U^{-1})^{-1}, (\Sigma^{-1}+U^{-1})^{-1} \Sigma^{-1} y) .
\end{align*}

Now suppose that the population is distributed in genotype space
as a Gaussian with covariance matrix $\Sigma$ and mean $y$.
Selection has the effect of multiplying this density by the fitness function and renormalizing,
so that if expected fitness of $x$ is proportional to $f(x;U,z)$
then the above argument shows that the next generation will be sampled from a Gaussian distribution
with covariance matrix $(\Sigma^{-1} + U^{-1})^{-1}$ 
and mean $z + (\Sigma^{-1}+U^{-1})^{-1} \Sigma^{-1} (y-z)$
Taking a sample of size $N$ to construct the next generation 
will produce something close to this but with a slightly (stochastically) deviating mean.
The next generation's mean is drawn from a Gaussian distribution with mean
with covariance matrix $(\Sigma^{-1} + U^{-1})^{-1}/N$ 
and mean $z + (\Sigma^{-1}+U^{-1})^{-1} \Sigma^{-1} (y-z)$.

Roughly, what is this doing?
Suppose that the population mean differs from the optimum by $\epsilon$,
that $\Sigma = \sigma^2 I$ and $U = I/\beta^2$ (so, stablizing selection happening on a distance scale of $\beta$).
Then the population mean gets closer to the optimum on average, moving to
$\epsilon/(1 + \sigma^2 \beta^2)$
and adds noise of size $(1/\beta) \sigma/\sqrt{N \sigma^2 + N 1/\beta^2}$.
At equilibrium, these two movements will be of the same order,
so that $\epsilon$ is of order $(\sigma/\sqrt{N}) \sqrt{1+\sigma^2 \beta^2}$.


\section{Away from the optimum}
\label{apx:away_from_opt}

Let two points  on $\optx$ be $x_1$ and $x_2$, let $\bar x = (x_1+x_2)/2$, and let $z=(x_2 - x_1)/2$.
Then with $D \Phi$ and $D^2 \Phi$ the first and second derivatives of $\Phi$, respectively,
then Taylor expanding about $x_1$ and $x_2$ finds that
\begin{align*}
    \Phi(\bar x) 
    &= \Phi(x_1) + D\Phi(x_1) \cdot z + \frac{1}{2} z^T D^2 \Phi(x_1) z + O(\|z\|^3) \\
    &= \Phi(x_2) - D\Phi(x_2) \cdot z + \frac{1}{2} z^T D^2 \Phi(x_2) z + O(\|z\|^3) .
\end{align*}
Now, since $\Phi(x_1) = \Phi(x_2) = \optph$ and
\begin{align*}
    D\Phi(x_2) = D\Phi(x_1) + 2 z^T D^2 \Phi(x_1) + O(\|z\|^2), \quad \text{and} \\
    D^2\Phi(x_2) = D^2\Phi(x_1) + O(\|z\|), \quad \text{and} \\
\end{align*}
adding together the two equations above and dividing by two gets that
\begin{align*}
    \Phi(\bar x) 
    &= \optph - \frac{3}{2} z^T D^2 \Phi(x_1) z + O(\|z\|^3) .
\end{align*}



\section{Differentiating the fitness function}
\label{apx:H_calc}

Suppose that $\rho(t) \ge 0$ is a weighting function on $[0,\infty)$
so that fitness is a function of $L^2(\rho)$ distance of the impulse response from optimal.
With $A_0$ a representative of the optimal set:
\begin{equation}
    \begin{aligned}
        D(A) 
        &:= 
        \int_0^\infty \rho(t) \left| h_A(t) - h_{A_0}(t) \right|^2 dt \\
        &:= 
        \int_0^\infty \rho(t) \left| C e^{At} B - C e^{A_0 t} B \right|^2 dt \\
        &= 
        \int_0^\infty \rho(t) \left| C \left( e^{At} - e^{A_0 t} \right) B \right|^2 dt \\
        &= 
        \int_0^\infty \rho(t) C \left( e^{At} - e^{A_0 t} \right) B B^T \left( e^{At} - e^{A_0 t} \right)^T C^T dt
    \end{aligned}
\end{equation}
How does this change with $A$?
Since
\begin{equation}
  \begin{aligned}
      \frac{d}{du} e^{(A+uZ)t} \vert_{u=0}
      &=
      \int_0^t e^{As} Z e^{A(t-s)} ds, 
  \end{aligned}
\end{equation}
we have that
\begin{equation}
  \begin{aligned}
      \frac{d}{du} D(A+uZ)\vert_{u=0}
      &=
        2 \int_0^\infty \rho(t) C \left( \int_0^t e^{As} Z e^{A(t-s)} ds \right) B B^T \left( e^{At} - e^{A_0 t} \right)^T C^T dt \\
      &=
        2 \int_0^\infty \rho(t) C \left( \int_0^t e^{As} Z e^{A(t-s)} ds \right) B \left( h_A(t) - h_{A_0}(t) \right)^T dt 
  \end{aligned}
\end{equation}
and, by differentiating this and supposing that $A$ is on the optimal set,
i.e., $h_A(t)=h_{A_0}(t)$, (so wolog $A=A_0$):
\begin{equation}
  \begin{aligned}
      \calH(Y,Z) &:= \frac{1}{2} \frac{d}{du} \frac{d}{dv} D(A_0+uY+vZ)\vert_{u=v=0} \\
      &=
        \int_0^\infty \rho(t) C 
        \left( \int_0^t e^{A_0 s} Y e^{A_0 (t-s)} ds \right) 
        B B^T 
        \left( \int_0^t e^{A_0 s} Z e^{A_0 (t-s)} ds \right)^T
        C^T dt  .
  \end{aligned}
\end{equation}
Here $\calH$ is the quadratic form underlying the Hamiltonian.
By defining $\Delta_{ij}$ to be the matrix with a 1 in the $(i,j)$th slot
and 0 elsewhere,
the coefficients of the quadratic form is
\begin{equation}
    \begin{aligned}
        H_{ij, k\ell}(A)
        &:=
        \calH(\Delta_{ij}, \Delta_{k\ell}) .
    \end{aligned}
\end{equation}

We could use this to compute the gradient of $D$,
or to get the quadratic approximation to $D$ near the optimal set.
To do so, it'd be nice to have a way to compute the inner integral above.
Suppose that we can diagonalize $A = U \Lambda U^{-1}$.
Then
\begin{equation} \label{eqn:exp_deriv}
  \begin{aligned}
      \int_0^t e^{As} Z e^{A(t-s)} ds 
      &=
      \int_0^t U e^{\Lambda s} U^{-1} Z U e^{\Lambda (t-s)} U^{-1} ds 
  \end{aligned}
\end{equation}
Now, notice that
\begin{equation}
  \begin{aligned}
      \int_0^t e^{s \lambda_i} e^{(t-s) \lambda_j} ds
      &=
      \frac{ e^{t \lambda_i} - e^{t \lambda_j} }{ \lambda_i - \lambda_j } .
  \end{aligned}
\end{equation}
Therefore, 
defining
\begin{equation}
    X_{ij}(t,Z) = \left( U^{-1} Z U \right)_{ij}
      \frac{ e^{t \lambda_i} - e^{t \lambda_j} }{ \lambda_i - \lambda_j } 
\end{equation}
moving the $U$ and $U^{-1}$ outside the integral and integrating we get that
\begin{equation}
  \begin{aligned}
      \int_0^t e^{As} Z e^{A(t-s)} ds 
      &=
      U X(t,Z) U^{-1} .
  \end{aligned}
\end{equation}

Following on from above, we see that if $Z=\Delta_{k \ell}$, then
\begin{equation}
  \begin{aligned}
      X_{ij}^{k\ell}(t) = 
      \frac{ e^{t \lambda_i} - e^{t \lambda_j} }{ \lambda_i - \lambda_j } 
      (U^{-1})_{\cdot k} U_{\ell \cdot},
  \end{aligned}
\end{equation}
where $U_{k \cdot}$ is the $k$th row of $U$,
and so
\begin{equation}
    \begin{aligned}
        H_{ij, k\ell}(A)
        &=
        \int_0^\infty
            \rho(t) C U X^{ij}(t) U^{-1} B B^T (U^{-1})^T X^{k\ell}(t)^T U^T C^T
        dt .
    \end{aligned}
\end{equation}
This implies that
\begin{equation}
    \begin{aligned}
        D(A_0+\epsilon Z)
        &\approx \epsilon^2\sum_{ijk\ell} H^{ij,k\ell} Z_{ij} Z_{k\ell} 
    \end{aligned}
\end{equation}
and so
\begin{equation}
    \begin{aligned}
        D(A_0+\epsilon Z)
        &\approx \epsilon^2\sum_{ijk\ell} H^{ij,k\ell} Z_{ij} Z_{k\ell} 
    \end{aligned}
\end{equation}

By section \ref{ss:quant_gen},
if we set $\Sigma=\sigma^2 I$ and $U=H$,
then a population at $A_0+Z$ experiences a restoring force of strength
$(I + \sigma^2 H^{-1})^{-1} Z$ (treating $Z$ as a vector and $H$ as an operator on these).
If $\sigma^2$ is small compared to $H^{-1}$
then this is approximately $-\sigma^2 H^{-1} Z$.
This suggests that the population mean follows an Ornstein-Uhlenbeck process,
as described (in different terms) in \citet{hansen1996translating}.

%\section{Hybrid Vigor: Unit Circle approach}
%
%If a fitness optimum is at the origin $(0,0) \in \R^{2}$,
%%and two populations have drifted away from the optimum by an distance of $r$, then the expected value of their $F_1$ hybrids is,
%%\begin{align*}
%%  \mathbb{E}\left[ \left\lVert \frac{1}{2} ((x_1,y_1) + (x_2,y_2))  \right\rVert \right] = \\
%%  \frac{\sqrt{2}}{8}\left(\sqrt{3\, r^2 - {\sin^{-1}\!\left(r\right)}^2 + r^4 - 2\, r\, \sin^{-1}\!\left(r\right)\, \sqrt{1 - r^2}} + \sqrt{{\sin^{-1}\!\left(r\right)}^2 + 5\, r^2 - r^4 + 2\, r\, \sin^{-1}\!\left(r\right)\, \sqrt{1 - r^2}}\right)
%%\end{align*} 
%%If $r < \sim 5.5$ then we will observe hybrid vigor, however if $r$ is sufficiently large, the hybrids will have lower fitness, on average. 
%and two populations have drifted away from the optimum by a distance of $r=1$,
%then $F_1$s will have an average fitness of,
%  \begin{align*}
%    \mathbb{E} \left[ d(F_1) \right] &= \int_{0}^{2\pi} \frac{1}{4 \pi} \left\lVert (1,0) + (\cos\theta,\sin\theta) \right\rVert d\theta \\
%    &= \frac{2}{\pi}
%  \end{align*}
%  %\begin{align*}
%  %  \mathbb{E} \left[ d(F_1)] \right] &= \int_{0}^{2\pi} \int_{0}^{2\pi} \frac{1}{8 \pi^{2}}\left\lVert  \left( \left( \cos(\theta_1), \sin(\theta_1) \right) , \left( \cos(\theta_2), \sin(\theta_2) \right) \right) \right\rVert d\theta_1 d\theta_2 \\
%  %  &= \cos\left(\frac{\pi}{2}\right) = \frac{\sqrt{2}}{2}
%  %\end{align*}
%%  \begin{align*}
%%    \mathbb{E} \left[ d(F_1)] \right] &\approx \sqrt{\int_{0}^{2\pi} \frac{1}{4 \pi}\left\lVert  \left( \cos(\pi), \sin(\pi) \right) , \left( \cos(\theta), \sin(\theta) \right) \right\rVert^2 d\theta} \\
%%    &= \sqrt{\frac{1}{2}}
%%  \end{align*}
%%Haploid $F_2$s will, on average, be a distance of $1$ half of the time, a distance of $0$ a quarter of the time, and a distance of $\sqrt{2}$ a quarter of the time. 
%
%  \begin{align*}
%    \mathbb{E} \left[ d(F_2) \right] &= \int_{0}^{2 \pi} \int_{0}^{2 \pi} \frac{1}{4 \pi^{2}} \sum_{i}^{2} \sum_{j}^{2} \sum_{k}^{2} \sum_{l}^{2} \frac{1}{32} \left\lVert \left( \cos(\theta_i) + \cos(\theta_k), \sin(\theta_j) + \sin(\theta_l) \right) \right\rVert d\theta_1 d\theta_2 \\ &= 0.6705
%  \end{align*}
%
%  \begin{align*}
%    \mathbb{E}\left[ d(F_{2_{\text{hap}}}) \right] &= \sqrt{\int_{0}^{2 \pi} \int_{0}^{2 \pi} \frac{1}{8 \pi^{2}} \cos(\theta_1)^{2} + \sin(\theta_2)^{2} d\theta_1 d\theta_2} \\
%    &= \cos \left( \frac{\pi}{2} \right) = \frac{\sqrt{2}}{2}
%  \end{align*}
%
%%  There are $16$ diploid $F_2$s, two have $F_0$ genotypes, two have $F_1$ genotpyes, eight contrain one $F_0$ and one $F_2$ haploid genotype (referred to as $H$; $\fit(H) = \sqrt{\frac{3}{8}}$), two are homozygous for an $F_2$ genotype (referred to as $W$; $\fit(W) = \frac{\sqrt{2}}{2}$), and finally two are heterozygous $F_2$s (referred to as $L$; $\fit(L) = \frac{1}{2}$.)
%  %The expected average distance of diploid $F_2$s is $0.6705$. 
%
%  \section{Hybrid Vigor: Probability}
%
%  \begin{align*}
%    X &\sim \mathcal{N} (x, \sigma^{2}) \\
%    Y &\sim \mathcal{N} (y, \sigma^{2}) \\
%    x &\sim \mathcal{N} (0, \eta^{2}) \\
%    y &\sim \mathcal{N}(0, \eta^{2}) \\
%    Z &= \frac{X+Y}{2} \rightarrow \mathbb{E} \left[ \lvert z \rvert^{2} \right] \\
%    Z &= \frac{x+y+U+V}{2} \\
%    \mathbb{E} \left[ \lvert X \rvert^{2} \right] &= \mathbb{E} \left[ \lvert x + U \rvert^{2} \right] = \mathbb{E} \left[ (x+U)^{T} (x+U) \right] \\
%    &= \mathbb{E} \left[ x^{T}x + U^{T}x + x^{T}U + U^{T}T \right] \\
%    &= \mathbb{E} \left[x^{T}x\right] + \mathbb{E} \left[U^{T}U\right] \\
%    &= d\eta^{2} + d\sigma^{2} \qquad d=\text{dimension} \\
%    X &\sim \mathcal{N}(0, \sigma^{2} + \eta^{2}) \\
%    Z &\sim \mathcal{N}\left(0, \frac{1}{4}(2 \eta^{2} + 2\sigma^{2})\right) \\
%    &\rightarrow \mathbb{E}\left[\lvert Z \rvert^{2} \right] \\
%    &= \frac{d}{2} \left(\eta^{2} + \sigma^{2} \right) \\
%    &= \frac{1}{2} \mathbb{E} \left[ \lvert X \rvert^{2} \right]
%  \end{align*}
\end{document}
